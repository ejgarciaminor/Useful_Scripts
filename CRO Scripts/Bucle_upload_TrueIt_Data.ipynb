{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODIGO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Año:  2024\n",
      "Mes:  2024\n",
      "Día inicio: 1\n",
      "Día fin: 23\n",
      "Subiendo datos del archivo de día:01\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:02\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:03\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:04\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:05\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:06\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:07\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:08\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:09\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:10\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:11\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:12\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:13\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:14\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:15\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:16\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:17\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:18\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:19\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:20\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:21\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:22\n",
      "Calls_per_queue UPLOADING\n",
      "Subiendo datos del archivo de día:23\n",
      "Calls_per_queue UPLOADING\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "from pandas.io import gbq\n",
    "from datetime import date, timedelta, datetime\n",
    "import ctypes\n",
    "import chardet\n",
    "import gcsfs\n",
    "from io import StringIO\n",
    "import google.auth\n",
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import logging\n",
    "import os\n",
    "import win32com.client\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "# Credentials to extract data from the Bucket\n",
    "fs = gcsfs.GCSFileSystem(project='nh-cro-forecast', token = r'C:\\Users\\ej.garcia\\OneDrive - Minor Hotels Europe & Americas\\Escritorio\\nh-cro-forecast-ec5c044f54cf.json')\n",
    "\n",
    "\n",
    "\n",
    "#DEFINIMOS AÑO, MES E INICIO DE DIA Y FINAL DE DIA\n",
    "Year = \"2024\"\n",
    "print('Año: ',Year)\n",
    "Month = \"05\"\n",
    "print(\"Mes: \",Year)\n",
    "\n",
    "inicio_dia = \"1\"\n",
    "print(\"Día inicio:\", inicio_dia)\n",
    "\n",
    "fin_dia = \"23\"\n",
    "print(\"Día fin:\", fin_dia)\n",
    "\n",
    "# INDICAMOS NUMERO DE QUERY QUE QUEREMOS EJECUTAR\n",
    "\n",
    "Query_number =  3\n",
    "\n",
    "\n",
    "\n",
    "if Query_number == 1:\n",
    "\n",
    "    for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Traffic_Calls UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Distribution/Calls_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['Date',\n",
    "                            'Service',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_slot',\n",
    "                            'Incoming_calls',\n",
    "                            'Answered_calls',\n",
    "                            'Abandoned_less_10s',\n",
    "                            'Abandoned_greater_10s']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Campaign':object,\n",
    "                                'Campaign_number':object,\n",
    "                                'Language':object,\n",
    "                                'IVR_option':object,\n",
    "                                'Time_slot':object,\n",
    "                                'Incoming_calls':int,\n",
    "                                'Answered_calls':int,\n",
    "                                'Abandoned_less_10s':int,\n",
    "                                'Abandoned_greater_10s':int,\n",
    "                                }\n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db['Service'] = Call_db['Service'].astype(str)\n",
    "                Call_db['Incoming_calls'] = Call_db['Incoming_calls'].astype(int)\n",
    "                Call_db['Answered_calls'] = Call_db['Answered_calls'].astype(int)\n",
    "                Call_db['Abandoned_less_10s'] = Call_db['Abandoned_less_10s'].astype(int)\n",
    "                Call_db['Abandoned_greater_10s'] = Call_db['Abandoned_greater_10s'].astype(int)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                # Call_db.to_gbq(destination_table='Evolution.Traffic_Calls',project_id='nh-cro-forecast', if_exists='append')\n",
    "                \n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Traffic_Calls UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Distribution/Calls_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['Date',\n",
    "                            'Service',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_slot',\n",
    "                            'Incoming_calls',\n",
    "                            'Answered_calls',\n",
    "                            'Abandoned_less_10s',\n",
    "                            'Abandoned_greater_10s']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Campaign':object,\n",
    "                                'Campaign_number':object,\n",
    "                                'Language':object,\n",
    "                                'IVR_option':object,\n",
    "                                'Time_slot':object,\n",
    "                                'Incoming_calls':int,\n",
    "                                'Answered_calls':int,\n",
    "                                'Abandoned_less_10s':int,\n",
    "                                'Abandoned_greater_10s':int,\n",
    "                                }\n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db['Service'] = Call_db['Service'].astype(str)\n",
    "                Call_db['Incoming_calls'] = Call_db['Incoming_calls'].astype(int)\n",
    "                Call_db['Answered_calls'] = Call_db['Answered_calls'].astype(int)\n",
    "                Call_db['Abandoned_less_10s'] = Call_db['Abandoned_less_10s'].astype(int)\n",
    "                Call_db['Abandoned_greater_10s'] = Call_db['Abandoned_greater_10s'].astype(int)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                # Call_db.to_gbq(destination_table='Evolution.Traffic_Calls',project_id='nh-cro-forecast', if_exists='append')\n",
    "\n",
    "elif Query_number == 2:\n",
    "         for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agent_total_breaks UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_By_Calls_And_Status/Agent_Total_Breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Agent_SAP',\n",
    "                            'Transactions',\n",
    "                            'Total_calls',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Transfer_in',\n",
    "                            'Transfer_out',\n",
    "                            'Session',\n",
    "                            'n_breaks',\n",
    "                            'Time_break_general',\n",
    "                            'Available',\n",
    "                            'Preview',\n",
    "                            'Time_on_call',\n",
    "                            'Wrap_up_time',\n",
    "                            'n_press',\n",
    "                            'Time_press',\n",
    "                            'n_sist',\n",
    "                            'Time_sist',\n",
    "                            'n_psup',\n",
    "                            'Time_psup',\n",
    "                            'n_ndef',\n",
    "                            'Time_ndef',\n",
    "                            'n_pfge',\n",
    "                            'Time_pfge',\n",
    "                            'n_pterr',\n",
    "                            'Time_pterr',\n",
    "                            'Time_administrative',\n",
    "                            'n_best_buddy_training',\n",
    "                            'time_best_buddy_training',\n",
    "                            'n_break',\n",
    "                            'Time_break',\n",
    "                            'n_classroom_training',\n",
    "                            'Time_classroom_training',\n",
    "                            'n_external_meeting',\n",
    "                            'Time_external_meeting',\n",
    "                            'n_internal_meeting',\n",
    "                            'Time_internal_meeting',\n",
    "                            'n_manual_dispatching',\n",
    "                            'Time_manual_dispatching',\n",
    "                            'n_other_department_gem',\n",
    "                            'Time_other_department_gem',\n",
    "                            'n_special_adminwork',\n",
    "                            'Time_special_adminwork',\n",
    "                            'n_support',\n",
    "                            'Time_support',\n",
    "                            'n_training_on_the_job',\n",
    "                            'Time_training_on_the_job',\n",
    "                            'n_visual_rest',\n",
    "                            'Time_visual_rest',\n",
    "                            'n_prelogout',\n",
    "                            'Time_prelogout',\n",
    "                            'n_unnasociated_dispatching',\n",
    "                            'Time_unnasociated_dispatching',\n",
    "                            'n_meeting',\n",
    "                            'Time_meeting',\n",
    "                            'n_processing_time',\n",
    "                            'Time_processing_time',\n",
    "                            'n_support_supervisor',\n",
    "                            'Time_support_supervisor',\n",
    "                            'n_mail_fax',\n",
    "                            'Time_mail_fax',\n",
    "                            'n_other_department_individual',\n",
    "                            'Time_other_deparment_individual',\n",
    "                            'n_inbox',\n",
    "                            'Time_inbox',\n",
    "                            'n_chat',\n",
    "                            'Time_chat',\n",
    "                            'n_sdc',\n",
    "                            'Time_sdc',\n",
    "                            'n_Followup',\n",
    "                            'Time_Followup',\n",
    "                            'Service',\n",
    "                            'ON_call_hold',\n",
    "                            'ON_call_active',\n",
    "                            'N_Assignation',\n",
    "                            'T_Assignation',\n",
    "                            'N_Stand_Prio',\n",
    "                            'T_Stand_Prio',\n",
    "                            'N_Bulk_and_Prio',\n",
    "                            'T_Bulk_and_Prio',\n",
    "                            'N_Overtime',\n",
    "                            'T_Overtime',\n",
    "                            'N_Site_Inspection',\n",
    "                            'T_Site_Inspection', \n",
    "                            'N_GEM_Disp', \n",
    "                            'T_GEM_Disp',\n",
    "                            'N_Multidestination',\n",
    "                            'T_Multidestination',\n",
    "                            'Number_Audits',\n",
    "                            'Time_Audits',\n",
    "                            'Number_Feedbacks',\n",
    "                            'Time_Feedbacks',\n",
    "                            'Number_Platforms',\n",
    "                            'Time_Platforms',\n",
    "                            'Number_Test',\n",
    "                            'Time_Test',\n",
    "                            'Number_Calibracion',\n",
    "                            'Time_Calibracion', \n",
    "                            'Number_Duplicated_y_Spam',\n",
    "                            'Time_Duplicated_y_Spam',\n",
    "                            'Number_Break_after_transaction',\n",
    "                            'Time_Break_after_transaction',\n",
    "                            'Number_Face_to_Face',\n",
    "                            'Time_Face_to_Face',\n",
    "                            'Number_Rest',\n",
    "                            'Time_Rest']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Session\"] = pd.to_datetime(doc[\"Session\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_break_general\"] = pd.to_datetime(doc[\"Time_break_general\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Available\"] = pd.to_datetime(doc[\"Available\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Preview\"] = pd.to_datetime(doc[\"Preview\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Wrap_up_time\"] = pd.to_datetime(doc[\"Wrap_up_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_press\"] = pd.to_datetime(doc[\"Time_press\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_sist\"] = pd.to_datetime(doc[\"Time_sist\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_psup\"] = pd.to_datetime(doc[\"Time_psup\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_ndef\"] = pd.to_datetime(doc[\"Time_ndef\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pfge\"] = pd.to_datetime(doc[\"Time_pfge\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pterr\"] = pd.to_datetime(doc[\"Time_pterr\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pterr\"] = pd.to_datetime(doc[\"Time_pterr\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_administrative\"] = pd.to_datetime(doc[\"Time_administrative\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"time_best_buddy_training\"] = pd.to_datetime(doc[\"time_best_buddy_training\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_break\"] = pd.to_datetime(doc[\"Time_break\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_classroom_training\"] = pd.to_datetime(doc[\"Time_classroom_training\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_external_meeting\"] = pd.to_datetime(doc[\"Time_external_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_internal_meeting\"] = pd.to_datetime(doc[\"Time_internal_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_manual_dispatching\"] = pd.to_datetime(doc[\"Time_manual_dispatching\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_other_department_gemsion\"] = pd.to_datetime(doc[\"Time_other_department_gem\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_special_adminwork\"] = pd.to_datetime(doc[\"Time_special_adminwork\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_support\"] = pd.to_datetime(doc[\"Time_support\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_training_on_the_job\"] = pd.to_datetime(doc[\"Time_training_on_the_job\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_visual_rest\"] = pd.to_datetime(doc[\"Time_visual_rest\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_prelogout\"] = pd.to_datetime(doc[\"Time_prelogout\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_unnasociated_dispatching\"] = pd.to_datetime(doc[\"Time_unnasociated_dispatching\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_meeting\"] = pd.to_datetime(doc[\"Time_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_processing_time\"] = pd.to_datetime(doc[\"Time_processing_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_support_supervisor\"] = pd.to_datetime(doc[\"Time_support_supervisor\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_mail_fax\"] = pd.to_datetime(doc[\"Time_mail_fax\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_other_deparment_individual\"] = pd.to_datetime(doc[\"Time_other_deparment_individual\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_inbox\"] = pd.to_datetime(doc[\"Time_inbox\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_chat\"] = pd.to_datetime(doc[\"Time_chat\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_sdc\"] = pd.to_datetime(doc[\"Time_sdc\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_Followup\"] = pd.to_datetime(doc[\"Time_Followup\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"ON_call_hold\"] = pd.to_datetime(doc[\"ON_call_hold\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"ON_call_active\"] = pd.to_datetime(doc[\"ON_call_active\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_on_call\"] = pd.to_datetime(doc[\"Time_on_call\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Assignation\"] = pd.to_datetime(doc[\"T_Assignation\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Stand_Prio\"] = pd.to_datetime(doc[\"T_Stand_Prio\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Bulk_and_Prio\"] = pd.to_datetime(doc[\"T_Bulk_and_Prio\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Overtime\"] = pd.to_datetime(doc[\"T_Overtime\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['T_Site_Inspection'] = pd.to_datetime(doc[\"T_Site_Inspection\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['T_GEM_Disp'] = pd.to_datetime(doc['T_GEM_Disp']).dt.strftime('%H:%M:%S')\n",
    "                doc['T_Multidestination'] = pd.to_datetime(doc['T_Multidestination']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Audits'] = pd.to_datetime(doc['Time_Audits']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Feedbacks'] = pd.to_datetime(doc['Time_Feedbacks']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Platforms'] = pd.to_datetime(doc['Time_Platforms']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Test'] = pd.to_datetime(doc['Time_Test']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Calibracion'] = pd.to_datetime(doc['Time_Calibracion']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Duplicated_y_Spam'] = pd.to_datetime(doc['Time_Duplicated_y_Spam']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Break_after_transaction'] = pd.to_datetime(doc['Time_Break_after_transaction']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Face_to_Face'] = pd.to_datetime(doc['Time_Face_to_Face']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Rest'] = pd.to_datetime(doc['Time_Rest']).dt.strftime('%H:%M:%S')\n",
    "                Output = doc.astype(str)\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Agent_SAP':object,\n",
    "                                'Transactions':object,\n",
    "                                'Total_calls':object,\n",
    "                                'Calls_in':object,\n",
    "                                'Calls_out':object,\n",
    "                                'Transfer_in':object,\n",
    "                                'Transfer_out':object,\n",
    "                                'Session':object,\n",
    "                                'n_breaks':object,\n",
    "                                'Time_break_general':object,\n",
    "                                'Available':object,\n",
    "                                'Preview':object,\n",
    "                                'Time_on_call':object,\n",
    "                                'Wrap_up_time':object,\n",
    "                                'n_press':object,\n",
    "                                'Time_press':object,\n",
    "                                'n_sist':object,\n",
    "                                'Time_sist':object,\n",
    "                                'n_psup':object,\n",
    "                                'Time_psup':object,\n",
    "                                'n_ndef':object,\n",
    "                                'Time_ndef':object,\n",
    "                                'n_pfge':object,\n",
    "                                'Time_pfge':object,\n",
    "                                'n_pterr':object,\n",
    "                                'Time_pterr':object,\n",
    "                                'Time_administrative':object,\n",
    "                                'n_best_buddy_training':object,\n",
    "                                'time_best_buddy_training':object,\n",
    "                                'n_break':object,\n",
    "                                'Time_break':object,\n",
    "                                'n_classroom_training':object,\n",
    "                                'Time_classroom_training':object,\n",
    "                                'n_external_meeting':object,\n",
    "                                'Time_external_meeting':object,\n",
    "                                'n_internal_meeting':object,\n",
    "                                'Time_internal_meeting':object,\n",
    "                                'n_manual_dispatching':object,\n",
    "                                'Time_manual_dispatching':object,\n",
    "                                'n_other_department_gem':object,\n",
    "                                'Time_other_department_gem':object,\n",
    "                                'n_special_adminwork':object,\n",
    "                                'Time_special_adminwork':object,\n",
    "                                'n_support':object,\n",
    "                                'Time_support':object,\n",
    "                                'n_training_on_the_job':object,\n",
    "                                'Time_training_on_the_job':object,\n",
    "                                'n_visual_rest':object,\n",
    "                                'Time_visual_rest':object,\n",
    "                                'n_prelogout':object,\n",
    "                                'Time_prelogout':object,\n",
    "                                'n_unnasociated_dispatching':object,\n",
    "                                'Time_unnasociated_dispatching':object,\n",
    "                                'n_meeting':object,\n",
    "                                'Time_meeting':object,\n",
    "                                'n_processing_time':object,\n",
    "                                'Time_processing_time':object,\n",
    "                                'n_support_supervisor':object,\n",
    "                                'Time_support_supervisor':object,\n",
    "                                'n_mail_fax':object,\n",
    "                                'Time_mail_fax':object,\n",
    "                                'n_other_department_individual':object,\n",
    "                                'Time_other_deparment_individual':object,\n",
    "                                'n_inbox':object,\n",
    "                                'Time_inbox':object,\n",
    "                                'n_chat':object,\n",
    "                                'Time_chat':object,\n",
    "                                'n_sdc':object,\n",
    "                                'Time_sdc':object,\n",
    "                                'n_Followup':object,\n",
    "                                'Time_Followup':object,\n",
    "                                'Service':object,\n",
    "                                'ON_call_hold':object,\n",
    "                                'ON_call_active':object,\n",
    "                                'N_Assignation': object,\n",
    "                                'T_Assignation': object,\n",
    "                                'N_Stand_Prio': object,\n",
    "                                'T_Stand_Prio':object,\n",
    "                                'N_Bulk_and_Prio':object,\n",
    "                                'T_Bulk_and_Prio':object,\n",
    "                                'N_Overtime':object,\n",
    "                                'T_Overtime':object,\n",
    "                                'N_Site_Inspection':object,\n",
    "                                'T_Site_Inspection':object, \n",
    "                                'N_GEM_Disp':object, \n",
    "                                'T_GEM_Disp':object,\n",
    "                                'N_Multidestination':object,\n",
    "                                'T_Multidestination':object,\n",
    "                                'Number_Audits':object,\n",
    "                                'Time_Audits':object,\n",
    "                                'Number_Feedbacks':object,\n",
    "                                'Time_Feedbacks':object,\n",
    "                                'Number_Platforms':object,\n",
    "                                'Time_Platforms':object,\n",
    "                                'Number_Test':object,\n",
    "                                'Time_Test':object,\n",
    "                                'Number_Calibracion':object,\n",
    "                                'Time_Calibracion':object, \n",
    "                                'Number_Duplicated_y_Spam':object,\n",
    "                                'Time_Duplicated_y_Spam':object,\n",
    "                                'Number_Break_after_transaction':object,\n",
    "                                'Time_Break_after_transaction':object,\n",
    "                                'Number_Face_to_Face':object,\n",
    "                                'Time_Face_to_Face':object,\n",
    "                                'Number_Rest':object,\n",
    "                                'Time_Rest':object} \n",
    "                Output[\"Time_other_department_gem\"] = pd.to_datetime(Output[\"Time_other_department_gem\"]).dt.strftime('%H:%M:%S')\n",
    "                d = []\n",
    "                for i in range(0, len(Output[\"Agent\"])):\n",
    "                    d.append(Output[\"Agent\"][i][:-1])\n",
    "                Output[\"Agent\"] = d\n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.iloc[:,:-1]\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace = True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Agent_total_breaks',project_id='nh-cro-forecast', if_exists='append')\n",
    "\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agent_total_breaks UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_By_Calls_And_Status/Agent_Total_Breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Agent_SAP',\n",
    "                            'Transactions',\n",
    "                            'Total_calls',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Transfer_in',\n",
    "                            'Transfer_out',\n",
    "                            'Session',\n",
    "                            'n_breaks',\n",
    "                            'Time_break_general',\n",
    "                            'Available',\n",
    "                            'Preview',\n",
    "                            'Time_on_call',\n",
    "                            'Wrap_up_time',\n",
    "                            'n_press',\n",
    "                            'Time_press',\n",
    "                            'n_sist',\n",
    "                            'Time_sist',\n",
    "                            'n_psup',\n",
    "                            'Time_psup',\n",
    "                            'n_ndef',\n",
    "                            'Time_ndef',\n",
    "                            'n_pfge',\n",
    "                            'Time_pfge',\n",
    "                            'n_pterr',\n",
    "                            'Time_pterr',\n",
    "                            'Time_administrative',\n",
    "                            'n_best_buddy_training',\n",
    "                            'time_best_buddy_training',\n",
    "                            'n_break',\n",
    "                            'Time_break',\n",
    "                            'n_classroom_training',\n",
    "                            'Time_classroom_training',\n",
    "                            'n_external_meeting',\n",
    "                            'Time_external_meeting',\n",
    "                            'n_internal_meeting',\n",
    "                            'Time_internal_meeting',\n",
    "                            'n_manual_dispatching',\n",
    "                            'Time_manual_dispatching',\n",
    "                            'n_other_department_gem',\n",
    "                            'Time_other_department_gem',\n",
    "                            'n_special_adminwork',\n",
    "                            'Time_special_adminwork',\n",
    "                            'n_support',\n",
    "                            'Time_support',\n",
    "                            'n_training_on_the_job',\n",
    "                            'Time_training_on_the_job',\n",
    "                            'n_visual_rest',\n",
    "                            'Time_visual_rest',\n",
    "                            'n_prelogout',\n",
    "                            'Time_prelogout',\n",
    "                            'n_unnasociated_dispatching',\n",
    "                            'Time_unnasociated_dispatching',\n",
    "                            'n_meeting',\n",
    "                            'Time_meeting',\n",
    "                            'n_processing_time',\n",
    "                            'Time_processing_time',\n",
    "                            'n_support_supervisor',\n",
    "                            'Time_support_supervisor',\n",
    "                            'n_mail_fax',\n",
    "                            'Time_mail_fax',\n",
    "                            'n_other_department_individual',\n",
    "                            'Time_other_deparment_individual',\n",
    "                            'n_inbox',\n",
    "                            'Time_inbox',\n",
    "                            'n_chat',\n",
    "                            'Time_chat',\n",
    "                            'n_sdc',\n",
    "                            'Time_sdc',\n",
    "                            'n_Followup',\n",
    "                            'Time_Followup',\n",
    "                            'Service',\n",
    "                            'ON_call_hold',\n",
    "                            'ON_call_active',\n",
    "                            'N_Assignation',\n",
    "                            'T_Assignation',\n",
    "                            'N_Stand_Prio',\n",
    "                            'T_Stand_Prio',\n",
    "                            'N_Bulk_and_Prio',\n",
    "                            'T_Bulk_and_Prio',\n",
    "                            'N_Overtime',\n",
    "                            'T_Overtime',\n",
    "                            'N_Site_Inspection',\n",
    "                            'T_Site_Inspection', \n",
    "                            'N_GEM_Disp', \n",
    "                            'T_GEM_Disp',\n",
    "                            'N_Multidestination',\n",
    "                            'T_Multidestination',\n",
    "                            'Number_Audits',\n",
    "                            'Time_Audits',\n",
    "                            'Number_Feedbacks',\n",
    "                            'Time_Feedbacks',\n",
    "                            'Number_Platforms',\n",
    "                            'Time_Platforms',\n",
    "                            'Number_Test',\n",
    "                            'Time_Test',\n",
    "                            'Number_Calibracion',\n",
    "                            'Time_Calibracion', \n",
    "                            'Number_Duplicated_y_Spam',\n",
    "                            'Time_Duplicated_y_Spam',\n",
    "                            'Number_Break_after_transaction',\n",
    "                            'Time_Break_after_transaction',\n",
    "                            'Number_Face_to_Face',\n",
    "                            'Time_Face_to_Face',\n",
    "                            'Number_Rest',\n",
    "                            'Time_Rest']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Session\"] = pd.to_datetime(doc[\"Session\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_break_general\"] = pd.to_datetime(doc[\"Time_break_general\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Available\"] = pd.to_datetime(doc[\"Available\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Preview\"] = pd.to_datetime(doc[\"Preview\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Wrap_up_time\"] = pd.to_datetime(doc[\"Wrap_up_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_press\"] = pd.to_datetime(doc[\"Time_press\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_sist\"] = pd.to_datetime(doc[\"Time_sist\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_psup\"] = pd.to_datetime(doc[\"Time_psup\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_ndef\"] = pd.to_datetime(doc[\"Time_ndef\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pfge\"] = pd.to_datetime(doc[\"Time_pfge\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pterr\"] = pd.to_datetime(doc[\"Time_pterr\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_pterr\"] = pd.to_datetime(doc[\"Time_pterr\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_administrative\"] = pd.to_datetime(doc[\"Time_administrative\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"time_best_buddy_training\"] = pd.to_datetime(doc[\"time_best_buddy_training\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_break\"] = pd.to_datetime(doc[\"Time_break\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_classroom_training\"] = pd.to_datetime(doc[\"Time_classroom_training\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_external_meeting\"] = pd.to_datetime(doc[\"Time_external_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_internal_meeting\"] = pd.to_datetime(doc[\"Time_internal_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_manual_dispatching\"] = pd.to_datetime(doc[\"Time_manual_dispatching\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_other_department_gemsion\"] = pd.to_datetime(doc[\"Time_other_department_gem\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_special_adminwork\"] = pd.to_datetime(doc[\"Time_special_adminwork\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_support\"] = pd.to_datetime(doc[\"Time_support\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_training_on_the_job\"] = pd.to_datetime(doc[\"Time_training_on_the_job\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_visual_rest\"] = pd.to_datetime(doc[\"Time_visual_rest\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_prelogout\"] = pd.to_datetime(doc[\"Time_prelogout\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_unnasociated_dispatching\"] = pd.to_datetime(doc[\"Time_unnasociated_dispatching\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_meeting\"] = pd.to_datetime(doc[\"Time_meeting\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_processing_time\"] = pd.to_datetime(doc[\"Time_processing_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_support_supervisor\"] = pd.to_datetime(doc[\"Time_support_supervisor\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_mail_fax\"] = pd.to_datetime(doc[\"Time_mail_fax\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_other_deparment_individual\"] = pd.to_datetime(doc[\"Time_other_deparment_individual\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_inbox\"] = pd.to_datetime(doc[\"Time_inbox\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_chat\"] = pd.to_datetime(doc[\"Time_chat\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_sdc\"] = pd.to_datetime(doc[\"Time_sdc\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_Followup\"] = pd.to_datetime(doc[\"Time_Followup\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"ON_call_hold\"] = pd.to_datetime(doc[\"ON_call_hold\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"ON_call_active\"] = pd.to_datetime(doc[\"ON_call_active\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_on_call\"] = pd.to_datetime(doc[\"Time_on_call\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Assignation\"] = pd.to_datetime(doc[\"T_Assignation\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Stand_Prio\"] = pd.to_datetime(doc[\"T_Stand_Prio\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Bulk_and_Prio\"] = pd.to_datetime(doc[\"T_Bulk_and_Prio\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Overtime\"] = pd.to_datetime(doc[\"T_Overtime\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['T_Site_Inspection'] = pd.to_datetime(doc[\"T_Site_Inspection\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['T_GEM_Disp'] = pd.to_datetime(doc['T_GEM_Disp']).dt.strftime('%H:%M:%S')\n",
    "                doc['T_Multidestination'] = pd.to_datetime(doc['T_Multidestination']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Audits'] = pd.to_datetime(doc['Time_Audits']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Feedbacks'] = pd.to_datetime(doc['Time_Feedbacks']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Platforms'] = pd.to_datetime(doc['Time_Platforms']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Test'] = pd.to_datetime(doc['Time_Test']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Calibracion'] = pd.to_datetime(doc['Time_Calibracion']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Duplicated_y_Spam'] = pd.to_datetime(doc['Time_Duplicated_y_Spam']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Break_after_transaction'] = pd.to_datetime(doc['Time_Break_after_transaction']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Face_to_Face'] = pd.to_datetime(doc['Time_Face_to_Face']).dt.strftime('%H:%M:%S')\n",
    "                doc['Time_Rest'] = pd.to_datetime(doc['Time_Rest']).dt.strftime('%H:%M:%S')\n",
    "                Output = doc.astype(str)\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Agent_SAP':object,\n",
    "                                'Transactions':object,\n",
    "                                'Total_calls':object,\n",
    "                                'Calls_in':object,\n",
    "                                'Calls_out':object,\n",
    "                                'Transfer_in':object,\n",
    "                                'Transfer_out':object,\n",
    "                                'Session':object,\n",
    "                                'n_breaks':object,\n",
    "                                'Time_break_general':object,\n",
    "                                'Available':object,\n",
    "                                'Preview':object,\n",
    "                                'Time_on_call':object,\n",
    "                                'Wrap_up_time':object,\n",
    "                                'n_press':object,\n",
    "                                'Time_press':object,\n",
    "                                'n_sist':object,\n",
    "                                'Time_sist':object,\n",
    "                                'n_psup':object,\n",
    "                                'Time_psup':object,\n",
    "                                'n_ndef':object,\n",
    "                                'Time_ndef':object,\n",
    "                                'n_pfge':object,\n",
    "                                'Time_pfge':object,\n",
    "                                'n_pterr':object,\n",
    "                                'Time_pterr':object,\n",
    "                                'Time_administrative':object,\n",
    "                                'n_best_buddy_training':object,\n",
    "                                'time_best_buddy_training':object,\n",
    "                                'n_break':object,\n",
    "                                'Time_break':object,\n",
    "                                'n_classroom_training':object,\n",
    "                                'Time_classroom_training':object,\n",
    "                                'n_external_meeting':object,\n",
    "                                'Time_external_meeting':object,\n",
    "                                'n_internal_meeting':object,\n",
    "                                'Time_internal_meeting':object,\n",
    "                                'n_manual_dispatching':object,\n",
    "                                'Time_manual_dispatching':object,\n",
    "                                'n_other_department_gem':object,\n",
    "                                'Time_other_department_gem':object,\n",
    "                                'n_special_adminwork':object,\n",
    "                                'Time_special_adminwork':object,\n",
    "                                'n_support':object,\n",
    "                                'Time_support':object,\n",
    "                                'n_training_on_the_job':object,\n",
    "                                'Time_training_on_the_job':object,\n",
    "                                'n_visual_rest':object,\n",
    "                                'Time_visual_rest':object,\n",
    "                                'n_prelogout':object,\n",
    "                                'Time_prelogout':object,\n",
    "                                'n_unnasociated_dispatching':object,\n",
    "                                'Time_unnasociated_dispatching':object,\n",
    "                                'n_meeting':object,\n",
    "                                'Time_meeting':object,\n",
    "                                'n_processing_time':object,\n",
    "                                'Time_processing_time':object,\n",
    "                                'n_support_supervisor':object,\n",
    "                                'Time_support_supervisor':object,\n",
    "                                'n_mail_fax':object,\n",
    "                                'Time_mail_fax':object,\n",
    "                                'n_other_department_individual':object,\n",
    "                                'Time_other_deparment_individual':object,\n",
    "                                'n_inbox':object,\n",
    "                                'Time_inbox':object,\n",
    "                                'n_chat':object,\n",
    "                                'Time_chat':object,\n",
    "                                'n_sdc':object,\n",
    "                                'Time_sdc':object,\n",
    "                                'n_Followup':object,\n",
    "                                'Time_Followup':object,\n",
    "                                'Service':object,\n",
    "                                'ON_call_hold':object,\n",
    "                                'ON_call_active':object,\n",
    "                                'N_Assignation': object,\n",
    "                                'T_Assignation': object,\n",
    "                                'N_Stand_Prio': object,\n",
    "                                'T_Stand_Prio':object,\n",
    "                                'N_Bulk_and_Prio':object,\n",
    "                                'T_Bulk_and_Prio':object,\n",
    "                                'N_Overtime':object,\n",
    "                                'T_Overtime':object,\n",
    "                                'N_Site_Inspection':object,\n",
    "                                'T_Site_Inspection':object, \n",
    "                                'N_GEM_Disp':object, \n",
    "                                'T_GEM_Disp':object,\n",
    "                                'N_Multidestination':object,\n",
    "                                'T_Multidestination':object,\n",
    "                                'Number_Audits':object,\n",
    "                                'Time_Audits':object,\n",
    "                                'Number_Feedbacks':object,\n",
    "                                'Time_Feedbacks':object,\n",
    "                                'Number_Platforms':object,\n",
    "                                'Time_Platforms':object,\n",
    "                                'Number_Test':object,\n",
    "                                'Time_Test':object,\n",
    "                                'Number_Calibracion':object,\n",
    "                                'Time_Calibracion':object, \n",
    "                                'Number_Duplicated_y_Spam':object,\n",
    "                                'Time_Duplicated_y_Spam':object,\n",
    "                                'Number_Break_after_transaction':object,\n",
    "                                'Time_Break_after_transaction':object,\n",
    "                                'Number_Face_to_Face':object,\n",
    "                                'Time_Face_to_Face':object,\n",
    "                                'Number_Rest':object,\n",
    "                                'Time_Rest':object} \n",
    "                Output[\"Time_other_department_gem\"] = pd.to_datetime(Output[\"Time_other_department_gem\"]).dt.strftime('%H:%M:%S')\n",
    "                d = []\n",
    "                for i in range(0, len(Output[\"Agent\"])):\n",
    "                    d.append(Output[\"Agent\"][i][:-1])\n",
    "                Output[\"Agent\"] = d\n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.iloc[:,:-1]\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace = True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Agent_total_breaks',project_id='nh-cro-forecast', if_exists='append')\n",
    "        \n",
    "elif Query_number == 3:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign/CDR_by_Agent_Campaign_Detail_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc.columns = ['Service',\n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Talk_time_in',\n",
    "                            'Talk_time_out',\n",
    "                            'Total_talk_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Talk_time_in\"] = pd.to_datetime(doc[\"Talk_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Talk_time_out\"] = pd.to_datetime(doc[\"Talk_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Total_talk_time\"] = pd.to_datetime(doc[\"Total_talk_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['Total_calls'] = doc['Calls_in'].astype(int) + doc['Calls_out'].astype(int)\n",
    "                Output = doc.astype(str)\n",
    "                Output\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Campaign':object,\n",
    "                                'Campaign_number':object,\n",
    "                                'Language':object,\n",
    "                                'IVR_option':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Calls_in':object,\n",
    "                                'Calls_out':object,\n",
    "                                'Total_calls':object,\n",
    "                                'Talk_time_in':object,\n",
    "                                'Talk_time_out':object,\n",
    "                                'Total_talk_time':object,\n",
    "                                } \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db[['Date', 'Service', 'Campaign', 'Campaign_number', 'Language', 'IVR_option','Agent', 'Agent_ID', 'Calls_in', 'Calls_out'\n",
    "                        , 'Total_calls', 'Talk_time_in', 'Talk_time_out', 'Total_talk_time']]\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Calls_per_queue',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign/CDR_by_Agent_Campaign_Detail_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc.columns = ['Service',\n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Talk_time_in',\n",
    "                            'Talk_time_out',\n",
    "                            'Total_talk_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Talk_time_in\"] = pd.to_datetime(doc[\"Talk_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Talk_time_out\"] = pd.to_datetime(doc[\"Talk_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Total_talk_time\"] = pd.to_datetime(doc[\"Total_talk_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc['Total_calls'] = doc['Calls_in'].astype(int) + doc['Calls_out'].astype(int)\n",
    "                Output = doc.astype(str)\n",
    "                Output\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Campaign':object,\n",
    "                                'Campaign_number':object,\n",
    "                                'Language':object,\n",
    "                                'IVR_option':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Calls_in':object,\n",
    "                                'Calls_out':object,\n",
    "                                'Total_calls':object,\n",
    "                                'Talk_time_in':object,\n",
    "                                'Talk_time_out':object,\n",
    "                                'Total_talk_time':object,\n",
    "                                } \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db[['Date', 'Service', 'Campaign', 'Campaign_number', 'Language', 'IVR_option','Agent', 'Agent_ID', 'Calls_in', 'Calls_out'\n",
    "                        , 'Total_calls', 'Talk_time_in', 'Talk_time_out', 'Total_talk_time']]\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Calls_per_queue',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 4:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('SLA_completed UPLOADING')\n",
    "                with fs.open('trueit_external/SLA_completed/SLA_Completed_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                File = doc\n",
    "                File.columns=['group',\n",
    "                            'Service',\n",
    "                            'Entry_date',\n",
    "                            'Entry_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID',\n",
    "                            'Alias',\n",
    "                            'Agent_distributed',\n",
    "                            'Distributed_date',\n",
    "                            'Distributed_hour',\n",
    "                            'Queue',\n",
    "                            'Completed',\n",
    "                            'Agent_completed',\n",
    "                            'Completed_date',\n",
    "                            'Completed_hour',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'due_on',\n",
    "                            'From_mail',\n",
    "                            'IN_OUT',\n",
    "                            'Total_time']\n",
    "                b = []\n",
    "                for i in range(len(File[\"due_on\"])):       \n",
    "                    b.append(File[\"due_on\"][i][File[\"due_on\"][i].rfind(\" \")+1:])\n",
    "                File[\"Due_on_hour\"] = b\n",
    "                c = []\n",
    "                for i in range(len(File[\"due_on\"])):\n",
    "                    c.append(File[\"due_on\"][i][:File[\"due_on\"][i].rfind(\" \")])\n",
    "                File[\"Due_on_date\"] = c\n",
    "                File = File.iloc[1:len(File)]\n",
    "                File.drop(['group'],axis=1,inplace=True)\n",
    "                File[\"Entry_date\"] = pd.to_datetime(File[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File[\"Completed_date\"] = pd.to_datetime(File[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File[\"Distributed_date\"] = pd.to_datetime(File[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File.drop(columns=['due_on'],inplace = True)\n",
    "                Output = File.astype(str)\n",
    "                convert_dict = {'Service':object,\n",
    "                                'Entry_date':object,\n",
    "                                'Entry_hour':object,\n",
    "                                'Activity_ID':object,\n",
    "                                'Case_ID':object,\n",
    "                                'Alias':object,\n",
    "                                'Agent_distributed':object,\n",
    "                                'Distributed_date':object,\n",
    "                                'Distributed_hour':object,\n",
    "                                'Queue':object,\n",
    "                                'Completed':object,\n",
    "                                'Agent_completed':object,\n",
    "                                'Completed_date':object,\n",
    "                                'Completed_hour':object,\n",
    "                                'Type':object,\n",
    "                                'Subtype':object,\n",
    "                                'From_mail':object,\n",
    "                                'IN_OUT':object,\n",
    "                                'Total_time':object,\n",
    "                                'Due_on_hour':object,\n",
    "                                'Due_on_date':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.reindex(columns = ['Service',\n",
    "                                                    'Entry_date',\n",
    "                                                    'Entry_hour',\n",
    "                                                    'Activity_ID',\n",
    "                                                    'Case_ID',\n",
    "                                                    'Alias',\n",
    "                                                    'Agent_distributed',\n",
    "                                                    'Distributed_date',\n",
    "                                                    'Distributed_hour',\n",
    "                                                    'Queue',\n",
    "                                                    'Completed',\n",
    "                                                    'Agent_completed',\n",
    "                                                    'Completed_date',\n",
    "                                                    'Completed_hour',\n",
    "                                                    'Type',\n",
    "                                                    'Subtype',\n",
    "                                                    'From_mail',\n",
    "                                                    'Due_on_date',\n",
    "                                                    'Due_on_hour',\n",
    "                                                    'IN_OUT',\n",
    "                                                    'Total_time'])\n",
    "                Call_db.to_gbq(destination_table='Evolution.SLA_completed',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('SLA_completed UPLOADING')\n",
    "                with fs.open('trueit_external/SLA_completed/SLA_Completed_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                File = doc\n",
    "                File.columns=['group',\n",
    "                            'Service',\n",
    "                            'Entry_date',\n",
    "                            'Entry_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID',\n",
    "                            'Alias',\n",
    "                            'Agent_distributed',\n",
    "                            'Distributed_date',\n",
    "                            'Distributed_hour',\n",
    "                            'Queue',\n",
    "                            'Completed',\n",
    "                            'Agent_completed',\n",
    "                            'Completed_date',\n",
    "                            'Completed_hour',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'due_on',\n",
    "                            'From_mail',\n",
    "                            'IN_OUT',\n",
    "                            'Total_time']\n",
    "                b = []\n",
    "                for i in range(len(File[\"due_on\"])):       \n",
    "                    b.append(File[\"due_on\"][i][File[\"due_on\"][i].rfind(\" \")+1:])\n",
    "                File[\"Due_on_hour\"] = b\n",
    "                c = []\n",
    "                for i in range(len(File[\"due_on\"])):\n",
    "                    c.append(File[\"due_on\"][i][:File[\"due_on\"][i].rfind(\" \")])\n",
    "                File[\"Due_on_date\"] = c\n",
    "                File = File.iloc[1:len(File)]\n",
    "                File.drop(['group'],axis=1,inplace=True)\n",
    "                File[\"Entry_date\"] = pd.to_datetime(File[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File[\"Completed_date\"] = pd.to_datetime(File[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File[\"Distributed_date\"] = pd.to_datetime(File[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                File.drop(columns=['due_on'],inplace = True)\n",
    "                Output = File.astype(str)\n",
    "                convert_dict = {'Service':object,\n",
    "                                'Entry_date':object,\n",
    "                                'Entry_hour':object,\n",
    "                                'Activity_ID':object,\n",
    "                                'Case_ID':object,\n",
    "                                'Alias':object,\n",
    "                                'Agent_distributed':object,\n",
    "                                'Distributed_date':object,\n",
    "                                'Distributed_hour':object,\n",
    "                                'Queue':object,\n",
    "                                'Completed':object,\n",
    "                                'Agent_completed':object,\n",
    "                                'Completed_date':object,\n",
    "                                'Completed_hour':object,\n",
    "                                'Type':object,\n",
    "                                'Subtype':object,\n",
    "                                'From_mail':object,\n",
    "                                'IN_OUT':object,\n",
    "                                'Total_time':object,\n",
    "                                'Due_on_hour':object,\n",
    "                                'Due_on_date':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.reindex(columns = ['Service',\n",
    "                                                    'Entry_date',\n",
    "                                                    'Entry_hour',\n",
    "                                                    'Activity_ID',\n",
    "                                                    'Case_ID',\n",
    "                                                    'Alias',\n",
    "                                                    'Agent_distributed',\n",
    "                                                    'Distributed_date',\n",
    "                                                    'Distributed_hour',\n",
    "                                                    'Queue',\n",
    "                                                    'Completed',\n",
    "                                                    'Agent_completed',\n",
    "                                                    'Completed_date',\n",
    "                                                    'Completed_hour',\n",
    "                                                    'Type',\n",
    "                                                    'Subtype',\n",
    "                                                    'From_mail',\n",
    "                                                    'Due_on_date',\n",
    "                                                    'Due_on_hour',\n",
    "                                                    'IN_OUT',\n",
    "                                                    'Total_time'])\n",
    "                Call_db.to_gbq(destination_table='Evolution.SLA_completed',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 5:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Codifications_Mails UPLOADING')\n",
    "                with fs.open('trueit_external/Mail_Codifications/Incoming_Category_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['grouplevel',\n",
    "                            'Group',\n",
    "                            'Group_2',\n",
    "                            'Agent',\n",
    "                            'Client',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'Category',\n",
    "                            'Subcategory',\n",
    "                            'Queue',\n",
    "                            'Created_on_date',\n",
    "                            'Created_on_hour',\n",
    "                            'Completed_on_date',\n",
    "                            'Completed_on_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID']\n",
    "                doc[\"Created_on_date\"] = pd.to_datetime(doc[\"Created_on_date\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_on_date\"] = pd.to_datetime(doc[\"Completed_on_date\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                Output.drop(['grouplevel'],axis = 1, inplace = True)\n",
    "                convert_dict = {'Group':object,\n",
    "                                'Group_2':object,\n",
    "                                'Agent':object,\n",
    "                                'Client':object,\n",
    "                                'Type':object,\n",
    "                                'Subtype':object,\n",
    "                                'Category':object,\n",
    "                                'Subcategory':object,\n",
    "                                'Queue':object,\n",
    "                                'Created_on_date':object,\n",
    "                                'Created_on_hour':object,\n",
    "                                'Completed_on_date':object,\n",
    "                                'Completed_on_hour':object,\n",
    "                                'Activity_ID':object,\n",
    "                                'Case_ID':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Codifications_Mails',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Codifications_Mails UPLOADING')\n",
    "                with fs.open('trueit_external/Mail_Codifications/Incoming_Category_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['grouplevel',\n",
    "                            'Group',\n",
    "                            'Group_2',\n",
    "                            'Agent',\n",
    "                            'Client',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'Category',\n",
    "                            'Subcategory',\n",
    "                            'Queue',\n",
    "                            'Created_on_date',\n",
    "                            'Created_on_hour',\n",
    "                            'Completed_on_date',\n",
    "                            'Completed_on_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID']\n",
    "                doc[\"Created_on_date\"] = pd.to_datetime(doc[\"Created_on_date\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_on_date\"] = pd.to_datetime(doc[\"Completed_on_date\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                Output.drop(['grouplevel'],axis = 1, inplace = True)\n",
    "                convert_dict = {'Group':object,\n",
    "                                'Group_2':object,\n",
    "                                'Agent':object,\n",
    "                                'Client':object,\n",
    "                                'Type':object,\n",
    "                                'Subtype':object,\n",
    "                                'Category':object,\n",
    "                                'Subcategory':object,\n",
    "                                'Queue':object,\n",
    "                                'Created_on_date':object,\n",
    "                                'Created_on_hour':object,\n",
    "                                'Completed_on_date':object,\n",
    "                                'Completed_on_hour':object,\n",
    "                                'Activity_ID':object,\n",
    "                                'Case_ID':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Codifications_Mails',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 6:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('a_Encuestas_Quality UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_FRONT/Survey_Front_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                column = ['Fecha',\n",
    "                        'ID_transaccion',\n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'ID_Agent',\n",
    "                        'Campaign',\n",
    "                        'ID_Campaign', \n",
    "                        'Language', \n",
    "                        'IVR_option', \n",
    "                        'Codification',\n",
    "                        'Answer_survey_transfered', \n",
    "                        'Non_answer_survey_transfered', \n",
    "                        'Question_1',\n",
    "                        'Mark_1', \n",
    "                        'Question_2', \n",
    "                        'Mark_2', \n",
    "                        'Question_3',\n",
    "                        'Mark_3']\n",
    "                doc.columns = column\n",
    "                doc = doc.iloc[:,[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,9]]\n",
    "                doc[\"Fecha\"] = pd.to_datetime(doc[\"Fecha\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Question_1\"] = doc[\"Question_1\"].replace('nan', '')\n",
    "                doc[\"Mark_1\"] = doc[\"Mark_1\"].replace('nan', '')\n",
    "                doc[\"Question_2\"] = doc[\"Question_2\"].replace('nan', '')\n",
    "                doc[\"Mark_2\"] = doc[\"Mark_2\"].replace('nan', '')\n",
    "                doc[\"Question_3\"] = doc[\"Question_3\"].replace('nan', '')\n",
    "                doc[\"Mark_3\"] = doc[\"Mark_3\"].replace('nan', '')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.a_Encuestas_Quality',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('a_Encuestas_Quality UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_FRONT/Survey_Front_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                column = ['Fecha',\n",
    "                        'ID_transaccion',\n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'ID_Agent',\n",
    "                        'Campaign',\n",
    "                        'ID_Campaign', \n",
    "                        'Language', \n",
    "                        'IVR_option', \n",
    "                        'Codification',\n",
    "                        'Answer_survey_transfered', \n",
    "                        'Non_answer_survey_transfered', \n",
    "                        'Question_1',\n",
    "                        'Mark_1', \n",
    "                        'Question_2', \n",
    "                        'Mark_2', \n",
    "                        'Question_3',\n",
    "                        'Mark_3']\n",
    "                doc.columns = column\n",
    "                doc = doc.iloc[:,[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,9]]\n",
    "                doc[\"Fecha\"] = pd.to_datetime(doc[\"Fecha\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Question_1\"] = doc[\"Question_1\"].replace('nan', '')\n",
    "                doc[\"Mark_1\"] = doc[\"Mark_1\"].replace('nan', '')\n",
    "                doc[\"Question_2\"] = doc[\"Question_2\"].replace('nan', '')\n",
    "                doc[\"Mark_2\"] = doc[\"Mark_2\"].replace('nan', '')\n",
    "                doc[\"Question_3\"] = doc[\"Question_3\"].replace('nan', '')\n",
    "                doc[\"Mark_3\"] = doc[\"Mark_3\"].replace('nan', '')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.a_Encuestas_Quality',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 7:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('NH_Encuestas UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_QUALITY/Survey_Quality_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                File = doc.iloc[0:,1:]\n",
    "                File.columns = ['Date',\n",
    "                                'Transaction_ID',\n",
    "                                'Service',\n",
    "                                'Agent',\n",
    "                                'Agent_ID',\n",
    "                                'Campaign',\n",
    "                                'Campaign_ID',\n",
    "                                'Language',\n",
    "                                'IVR_option',\n",
    "                                'Closure',\n",
    "                                'N_survey_transfered',\n",
    "                                'N_survey_transfered_non_answer',\n",
    "                                'Question_1',\n",
    "                                'Mark_question_1',\n",
    "                                'Question_2',\n",
    "                                'Mark_question_2']\n",
    "                File['Date'] = pd.to_datetime(File[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = File.astype(str)\n",
    "                Out_1 = Output[['Date', \n",
    "                                'Transaction_ID', \n",
    "                                'Service', \n",
    "                                'Agent', \n",
    "                                'Agent_ID',\n",
    "                                'Campaign',\n",
    "                                'Campaign_ID',\n",
    "                                'Language',\n",
    "                                'IVR_option',\n",
    "                                'N_survey_transfered',\n",
    "                                'N_survey_transfered_non_answer',\n",
    "                                'Question_1',\n",
    "                                'Mark_question_1',\n",
    "                                'Question_2',\n",
    "                                'Mark_question_2',\n",
    "                                'Closure']]\n",
    "                Out_2 = Out_1.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None])\n",
    "                Out_2.to_gbq(destination_table='Evolution.NH_Encuestas',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('NH_Encuestas UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_QUALITY/Survey_Quality_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                File = doc.iloc[0:,1:]\n",
    "                File.columns = ['Date',\n",
    "                                'Transaction_ID',\n",
    "                                'Service',\n",
    "                                'Agent',\n",
    "                                'Agent_ID',\n",
    "                                'Campaign',\n",
    "                                'Campaign_ID',\n",
    "                                'Language',\n",
    "                                'IVR_option',\n",
    "                                'Closure',\n",
    "                                'N_survey_transfered',\n",
    "                                'N_survey_transfered_non_answer',\n",
    "                                'Question_1',\n",
    "                                'Mark_question_1',\n",
    "                                'Question_2',\n",
    "                                'Mark_question_2']\n",
    "                File['Date'] = pd.to_datetime(File[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = File.astype(str)\n",
    "                Out_1 = Output[['Date', \n",
    "                                'Transaction_ID', \n",
    "                                'Service', \n",
    "                                'Agent', \n",
    "                                'Agent_ID',\n",
    "                                'Campaign',\n",
    "                                'Campaign_ID',\n",
    "                                'Language',\n",
    "                                'IVR_option',\n",
    "                                'N_survey_transfered',\n",
    "                                'N_survey_transfered_non_answer',\n",
    "                                'Question_1',\n",
    "                                'Mark_question_1',\n",
    "                                'Question_2',\n",
    "                                'Mark_question_2',\n",
    "                                'Closure']]\n",
    "                Out_2 = Out_1.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None])\n",
    "                Out_2.to_gbq(destination_table='Evolution.NH_Encuestas',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 8:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_3_NBA_Survey UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_NBA/Calls_Survey_NBA_service_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Fecha\":\"Date\",\n",
    "                                        \"Servicio\":\"Service\",\n",
    "                                        \"Agente\":\"Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"Idioma\":\"Language\",\n",
    "                                        \"IdTransaccion\":\"ID_Transaction\",\n",
    "                                        \"ID Agente\":\"ID_Agent\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"IVR Option\":\"IVR_Option\",\n",
    "                                        \"N encuestas transferidas\":\"Survey_transfered\",\n",
    "                                        \"N encuestas transferidas NC\":\"Survey_transfered_not_answered\",\n",
    "                                        \"Pregunta 1\":\"Question_1\",\n",
    "                                        \"Nota Pregunta 1\":\"Question_1_mark\",\n",
    "                                        \"Pregunta 2\":\"Question_2\",\n",
    "                                        \"Nota Pregunta 2\":\"Question_2_mark\",\n",
    "                                        \"Pregunta 3\":\"Question_3\",\n",
    "                                        \"Nota Pregunta 3\":\"Question_3_mark\"})\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_3_NBA_Survey',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_3_NBA_Survey UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_NBA/Calls_Survey_NBA_service_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Fecha\":\"Date\",\n",
    "                                        \"Servicio\":\"Service\",\n",
    "                                        \"Agente\":\"Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"Idioma\":\"Language\",\n",
    "                                        \"IdTransaccion\":\"ID_Transaction\",\n",
    "                                        \"ID Agente\":\"ID_Agent\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"IVR Option\":\"IVR_Option\",\n",
    "                                        \"N encuestas transferidas\":\"Survey_transfered\",\n",
    "                                        \"N encuestas transferidas NC\":\"Survey_transfered_not_answered\",\n",
    "                                        \"Pregunta 1\":\"Question_1\",\n",
    "                                        \"Nota Pregunta 1\":\"Question_1_mark\",\n",
    "                                        \"Pregunta 2\":\"Question_2\",\n",
    "                                        \"Nota Pregunta 2\":\"Question_2_mark\",\n",
    "                                        \"Pregunta 3\":\"Question_3\",\n",
    "                                        \"Nota Pregunta 3\":\"Question_3_mark\"})\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_3_NBA_Survey',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 9:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_4_CAT_Survey UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_NBA/Calls_Survey_CAT_service_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')  \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Fecha\":\"Date\",\n",
    "                                        \"Servicio\":\"Service\",\n",
    "                                        \"Agente\":\"Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"Idioma\":\"Language\",\n",
    "                                        \"IdTransaccion\":\"ID_Transaction\",\n",
    "                                        \"ID Agente\":\"ID_Agent\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"IVR Option\":\"IVR_Option\",\n",
    "                                        \"N encuestas transferidas\":\"Survey_transfered\",\n",
    "                                        \"N encuestas transferidas NC\":\"Survey_transfered_not_answered\",\n",
    "                                        \"Pregunta 1\":\"Question_1\",\n",
    "                                        \"Nota Pregunta 1\":\"Question_1_mark\",\n",
    "                                        \"Pregunta 2\":\"Question_2\",\n",
    "                                        \"Nota Pregunta 2\":\"Question_2_mark\",\n",
    "                                        \"Pregunta 3\":\"Question_3\",\n",
    "                                        \"Nota Pregunta 3\":\"Question_3_mark\"})\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_4_CAT_Survey',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_4_CAT_Survey UPLOADING')\n",
    "                with fs.open('trueit_external/Survey_NBA/Calls_Survey_CAT_service_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')  \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Fecha\":\"Date\",\n",
    "                                        \"Servicio\":\"Service\",\n",
    "                                        \"Agente\":\"Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"Idioma\":\"Language\",\n",
    "                                        \"IdTransaccion\":\"ID_Transaction\",\n",
    "                                        \"ID Agente\":\"ID_Agent\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"IVR Option\":\"IVR_Option\",\n",
    "                                        \"N encuestas transferidas\":\"Survey_transfered\",\n",
    "                                        \"N encuestas transferidas NC\":\"Survey_transfered_not_answered\",\n",
    "                                        \"Pregunta 1\":\"Question_1\",\n",
    "                                        \"Nota Pregunta 1\":\"Question_1_mark\",\n",
    "                                        \"Pregunta 2\":\"Question_2\",\n",
    "                                        \"Nota Pregunta 2\":\"Question_2_mark\",\n",
    "                                        \"Pregunta 3\":\"Question_3\",\n",
    "                                        \"Nota Pregunta 3\":\"Question_3_mark\"})\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_4_CAT_Survey',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 10:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_6_Dispatching_oficial UPLOADING')\n",
    "                with fs.open('trueit_external/Dispatching/Dispatching_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1', dtype=str)\n",
    "                doc = doc.astype(str)\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_6_Dispatching_oficial',project_id='nh-cro-forecast', if_exists='append',location = 'EU') \n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_6_Dispatching_oficial UPLOADING')\n",
    "                with fs.open('trueit_external/Dispatching/Dispatching_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1', dtype=str)\n",
    "                doc = doc.astype(str)\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_6_Dispatching_oficial',project_id='nh-cro-forecast', if_exists='append',location = 'EU') \n",
    "elif Query_number == 11:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_1_NBA_Calls_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications_NBA/Calls_Codifications_NBA_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ID Campaign\":\"ID_Campaign\",\n",
    "                                        \"ivr_opt\":\"IVR_Option\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GPDR_conditions\"})\n",
    "\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Hour\"] = pd.to_datetime(doc[\"Hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Contact_time\"] = pd.to_datetime(doc[\"Contact_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_1_NBA_Calls_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                with fs.open('trueit_external/Calls_Codifications_NBA/Calls_Codifications_NBA_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ID Campaign\":\"ID_Campaign\",\n",
    "                                        \"ivr_opt\":\"IVR_Option\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GPDR_conditions\"})\n",
    "\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Hour\"] = pd.to_datetime(doc[\"Hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Contact_time\"] = pd.to_datetime(doc[\"Contact_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_1_NBA_Calls_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 12:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_2_NBA_Mails_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Mails_Codifications_NBA/Mails_Codifications_NBA_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ENTRY_DATE\":\"Entry_date\",\n",
    "                                        \"ENTRY_HOUR\":\"Entry_hour\",\n",
    "                                        \"ACTIVITY_ID\":\"Activity_ID\",\n",
    "                                        \"CASE_ID\":\"Case_ID\",\n",
    "                                        \"AGENT_DISTRIBUTED\":\"Agent_distributed\",\n",
    "                                        \"DISTRIBUTED_DATE\":\"Distributed_date\",\n",
    "                                        \"DISTRIBUTED_HOUR\":\"Distributed_hour\",\n",
    "                                        \"QUEUE\":\"Queue\",\n",
    "                                        \"COMPLETED\":\"Completed\",\n",
    "                                        \"AGENT_COMPLETED\":\"Agent_completed\",\n",
    "                                        \"COMPLETED_DATE\":\"Completed_date\",\n",
    "                                        \"COMPLETED_HOUR\":\"Completed_hour\",\n",
    "                                        \"DIRECTION\":\"Direction\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GPDR_conditions\"})\n",
    "                doc[\"Entry_date\"] = pd.to_datetime(doc[\"Entry_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Entry_hour\"] = pd.to_datetime(doc[\"Entry_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Distributed_date\"] = pd.to_datetime(doc[\"Distributed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Distributed_hour\"] = pd.to_datetime(doc[\"Distributed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Completed_date\"] = pd.to_datetime(doc[\"Completed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_hour\"] = pd.to_datetime(doc[\"Completed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_2_NBA_Mails_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_2_NBA_Mails_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Mails_Codifications_NBA/Mails_Codifications_NBA_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ENTRY_DATE\":\"Entry_date\",\n",
    "                                        \"ENTRY_HOUR\":\"Entry_hour\",\n",
    "                                        \"ACTIVITY_ID\":\"Activity_ID\",\n",
    "                                        \"CASE_ID\":\"Case_ID\",\n",
    "                                        \"AGENT_DISTRIBUTED\":\"Agent_distributed\",\n",
    "                                        \"DISTRIBUTED_DATE\":\"Distributed_date\",\n",
    "                                        \"DISTRIBUTED_HOUR\":\"Distributed_hour\",\n",
    "                                        \"QUEUE\":\"Queue\",\n",
    "                                        \"COMPLETED\":\"Completed\",\n",
    "                                        \"AGENT_COMPLETED\":\"Agent_completed\",\n",
    "                                        \"COMPLETED_DATE\":\"Completed_date\",\n",
    "                                        \"COMPLETED_HOUR\":\"Completed_hour\",\n",
    "                                        \"DIRECTION\":\"Direction\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GPDR_conditions\"})\n",
    "                doc[\"Entry_date\"] = pd.to_datetime(doc[\"Entry_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Entry_hour\"] = pd.to_datetime(doc[\"Entry_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Distributed_date\"] = pd.to_datetime(doc[\"Distributed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Distributed_hour\"] = pd.to_datetime(doc[\"Distributed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Completed_date\"] = pd.to_datetime(doc[\"Completed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_hour\"] = pd.to_datetime(doc[\"Completed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_2_NBA_Mails_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 13:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('d_1_Traduccion_mails UPLOADING')\n",
    "                with fs.open('trueit_external/Mail_Traductions/Mails_Traducciones_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Time\"] = pd.to_datetime(doc[\"Time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Queue_time\"] = pd.to_datetime(doc[\"Queue_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_total_mail_time\"] = pd.to_datetime(doc[\"Agent_total_mail_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_real_mail_time\"] = pd.to_datetime(doc[\"Agent_real_mail_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Traduction_time\"] = pd.to_datetime(doc[\"Traduction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_traduction_time\"] = pd.to_datetime(doc[\"Agent_traduction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.d_1_Traduccion_mails',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('d_1_Traduccion_mails UPLOADING')\n",
    "                with fs.open('trueit_external/Mail_Traductions/Mails_Traducciones_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Time\"] = pd.to_datetime(doc[\"Time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Queue_time\"] = pd.to_datetime(doc[\"Queue_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_total_mail_time\"] = pd.to_datetime(doc[\"Agent_total_mail_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_real_mail_time\"] = pd.to_datetime(doc[\"Agent_real_mail_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Traduction_time\"] = pd.to_datetime(doc[\"Traduction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agent_traduction_time\"] = pd.to_datetime(doc[\"Agent_traduction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.d_1_Traduccion_mails',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 14:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_9_Calls_Cod_Transaction UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications_Transaction/Calls_Cod_Transaction_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ID Agent\":\"ID_Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"LANGUAGE\":\"Language\",\n",
    "                                        \"IVR OPTION\":\"IVR_Option\",\n",
    "                                        \"LLAMADAS_IN\":\"Calls_IN\",\n",
    "                                        \"LLAMADAS_OUT\":\"Calls_OUT\",\n",
    "                                        \"T_DURACION_IN\":\"T_Duration_IN\",\n",
    "                                        \"T_DURACION_OUT\":\"T_Duration_OUT\",\n",
    "                                        \"T_DURACION\":\"Time_Duration\"})\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format=\"%d/%m/%Y\").dt.strftime('%Y-%m-%d')\n",
    "                doc[\"T_Duration_IN\"] = pd.to_datetime(doc[\"T_Duration_IN\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Duration_OUT\"] = pd.to_datetime(doc[\"T_Duration_OUT\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_Duration\"] = pd.to_datetime(doc[\"Time_Duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_9_Calls_Cod_Transaction',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_9_Calls_Cod_Transaction UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications_Transaction/Calls_Cod_Transaction_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"ID Agent\":\"ID_Agent\",\n",
    "                                        \"Campaña\":\"Campaign\",\n",
    "                                        \"ID Campaña\":\"ID_Campaign\",\n",
    "                                        \"LANGUAGE\":\"Language\",\n",
    "                                        \"IVR OPTION\":\"IVR_Option\",\n",
    "                                        \"LLAMADAS_IN\":\"Calls_IN\",\n",
    "                                        \"LLAMADAS_OUT\":\"Calls_OUT\",\n",
    "                                        \"T_DURACION_IN\":\"T_Duration_IN\",\n",
    "                                        \"T_DURACION_OUT\":\"T_Duration_OUT\",\n",
    "                                        \"T_DURACION\":\"Time_Duration\"})\n",
    "                doc = doc.astype(str)\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format=\"%d/%m/%Y\").dt.strftime('%Y-%m-%d')\n",
    "                doc[\"T_Duration_IN\"] = pd.to_datetime(doc[\"T_Duration_IN\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"T_Duration_OUT\"] = pd.to_datetime(doc[\"T_Duration_OUT\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_Duration\"] = pd.to_datetime(doc[\"Time_Duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.to_gbq(destination_table='Evolution.e_9_Calls_Cod_Transaction',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 15:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_10_Coordination_status UPLOADING')\n",
    "                with fs.open('trueit_external/Coordination_breaks/Status_Coordination_breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')       \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)\n",
    "                r[\"Date\"] = pd.to_datetime(r[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_date\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_hour\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_status_date\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"End_status_hour\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_10_Coordination_status',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_10_Coordination_status UPLOADING')\n",
    "                with fs.open('trueit_external/Coordination_breaks/Status_Coordination_breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')       \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)\n",
    "                r[\"Date\"] = pd.to_datetime(r[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_date\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_hour\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_status_date\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"End_status_hour\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_10_Coordination_status',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 16:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_11_CAT_Mails_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Mails_Codifications_CAT/Mails_Codifications_CAT_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Service\":\"Service\",\n",
    "                                        \"ENTRY_DATE\":\"Entry_date\",\n",
    "                                        \"ENTRY_HOUR\":\"Entry_hour\",\n",
    "                                        \"ACTIVITY_ID\":\"Activity_ID\",\n",
    "                                        \"CASE_ID\":\"Case_ID\",\n",
    "                                        \"Alias\":\"Alias\",\n",
    "                                        \"AGENT_DISTRIBUTED\":\"Agent_distributed\",\n",
    "                                        \"DISTRIBUTED_DATE\":\"Distributed_date\",\n",
    "                                        \"DISTRIBUTED_HOUR\":\"Distributed_hour\",\n",
    "                                        \"QUEUE\":\"Queue\",\n",
    "                                        \"COMPLETED\":\"Completed\",\n",
    "                                        \"AGENT_COMPLETED\":\"Agent_completed\",\n",
    "                                        \"COMPLETED_DATE\":\"Completed_date\",\n",
    "                                        \"COMPLETED_HOUR\":\"Completed_hour\",\n",
    "                                        \"Subtype\":\"Subtype\",\n",
    "                                        \"DIRECTION\":\"Direction\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GDPR_conditions\",\n",
    "                                        \"Remarks\":\"Remarks\",\n",
    "                                        \"PID empresa\":\"PID\",\n",
    "                                        \"nombre empresa\":\"Enterprise_name\",\n",
    "                                        \"categoria A/B/C\":\"Category\",\n",
    "                                        \"terms & conditions aceptados yes/no\":\"Terms_and_condition\",\n",
    "                                        \"credentials yes/no\":\"Credentials\",\n",
    "                                        \"total revenue last year\":\"Revenue_last_year\",\n",
    "                                        \"email\":\"Email\",\n",
    "                                    })\n",
    "                doc[\"Entry_date\"] = pd.to_datetime(doc[\"Entry_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Entry_hour\"] = pd.to_datetime(doc[\"Entry_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Distributed_date\"] = pd.to_datetime(doc[\"Distributed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Distributed_hour\"] = pd.to_datetime(doc[\"Distributed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Completed_date\"] = pd.to_datetime(doc[\"Completed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_hour\"] = pd.to_datetime(doc[\"Completed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_11_CAT_Mails_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_11_CAT_Mails_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Mails_Codifications_CAT/Mails_Codifications_CAT_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Service\":\"Service\",\n",
    "                                        \"ENTRY_DATE\":\"Entry_date\",\n",
    "                                        \"ENTRY_HOUR\":\"Entry_hour\",\n",
    "                                        \"ACTIVITY_ID\":\"Activity_ID\",\n",
    "                                        \"CASE_ID\":\"Case_ID\",\n",
    "                                        \"Alias\":\"Alias\",\n",
    "                                        \"AGENT_DISTRIBUTED\":\"Agent_distributed\",\n",
    "                                        \"DISTRIBUTED_DATE\":\"Distributed_date\",\n",
    "                                        \"DISTRIBUTED_HOUR\":\"Distributed_hour\",\n",
    "                                        \"QUEUE\":\"Queue\",\n",
    "                                        \"COMPLETED\":\"Completed\",\n",
    "                                        \"AGENT_COMPLETED\":\"Agent_completed\",\n",
    "                                        \"COMPLETED_DATE\":\"Completed_date\",\n",
    "                                        \"COMPLETED_HOUR\":\"Completed_hour\",\n",
    "                                        \"Subtype\":\"Subtype\",\n",
    "                                        \"DIRECTION\":\"Direction\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_Cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GDPR_conditions\",\n",
    "                                        \"Remarks\":\"Remarks\",\n",
    "                                        \"PID empresa\":\"PID\",\n",
    "                                        \"nombre empresa\":\"Enterprise_name\",\n",
    "                                        \"categoria A/B/C\":\"Category\",\n",
    "                                        \"terms & conditions aceptados yes/no\":\"Terms_and_condition\",\n",
    "                                        \"credentials yes/no\":\"Credentials\",\n",
    "                                        \"total revenue last year\":\"Revenue_last_year\",\n",
    "                                        \"email\":\"Email\",\n",
    "                                    })\n",
    "                doc[\"Entry_date\"] = pd.to_datetime(doc[\"Entry_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Entry_hour\"] = pd.to_datetime(doc[\"Entry_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Distributed_date\"] = pd.to_datetime(doc[\"Distributed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Distributed_hour\"] = pd.to_datetime(doc[\"Distributed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Completed_date\"] = pd.to_datetime(doc[\"Completed_date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Completed_hour\"] = pd.to_datetime(doc[\"Completed_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_11_CAT_Mails_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 17:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_12_CAT_Calls_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications_CAT/Calls_Codifications_CAT_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Service\":\"Service\",\n",
    "                                        \"Date\":\"Date\",\n",
    "                                        \"Hour\":\"Hour\",\n",
    "                                        \"Agent\":\"Agent\",\n",
    "                                        \"ID_Agent\":\"Agent_ID\",\n",
    "                                        \"Campaign\":\"Campaign\",\n",
    "                                        \"ID Campaign\":\"ID_Campaign\",\n",
    "                                        \"Lang\":\"Lang\",\n",
    "                                        \"ivr_opt\":\"IVR_Option\",\n",
    "                                        \"Type\":\"Type\",\n",
    "                                        \"Transaction_time\":\"Transaction_time\",\n",
    "                                        \"Contact_time\":\"Contact_time\",\n",
    "                                        \"Closure\":\"Closure\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GDPR_conditions\",\n",
    "                                        \"Remarks\":\"Remarks\",\n",
    "                                        \"PID empresa\":\"PID\",\n",
    "                                        \"nombre empresa\":\"Enterprise_name\",\n",
    "                                        \"categoria A/B/C\":\"Category\",\n",
    "                                        \"terms & conditions aceptados yes/no\":\"Terms_and_condition\",\n",
    "                                        \"credentials yes/no\":\"Credentials\",\n",
    "                                        \"total revenue last year\":\"Revenue_last_year\",\n",
    "                                        \"email\":\"Email\",\n",
    "                                    })\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Hour\"] = pd.to_datetime(doc[\"Hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Contact_time\"] = pd.to_datetime(doc[\"Contact_time\"]).dt.strftime('%H:%M:%S')\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_12_CAT_Calls_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_12_CAT_Calls_Codification UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications_CAT/Calls_Codifications_CAT_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[0:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc=doc.rename(columns={\"Service\":\"Service\",\n",
    "                                        \"Date\":\"Date\",\n",
    "                                        \"Hour\":\"Hour\",\n",
    "                                        \"Agent\":\"Agent\",\n",
    "                                        \"ID_Agent\":\"Agent_ID\",\n",
    "                                        \"Campaign\":\"Campaign\",\n",
    "                                        \"ID Campaign\":\"ID_Campaign\",\n",
    "                                        \"Lang\":\"Lang\",\n",
    "                                        \"ivr_opt\":\"IVR_Option\",\n",
    "                                        \"Type\":\"Type\",\n",
    "                                        \"Transaction_time\":\"Transaction_time\",\n",
    "                                        \"Contact_time\":\"Contact_time\",\n",
    "                                        \"Closure\":\"Closure\",\n",
    "                                        \"Your company has used NH/contract with us in the past\":\"Question1_NH_contract_company\",\n",
    "                                        \"What cities do they usually travel to?\":\"Question2_cities\",\n",
    "                                        \"Are you considering a particular property or several? Which / Which ones?\":\"Question3_Properties\",\n",
    "                                        \"Could you tell us in general how many overnight stays you think you would make at the end of the year with us?\":\"Question4_Overnight_stays_per_year\",\n",
    "                                        \"Do you make your reservations directly or through an intermediary?\":\"Question5_Reservations_intermediary\",\n",
    "                                        \"Could you tell us the name of the reservations intermediary?\":\"Question6_Reservations_intermediary_name\",\n",
    "                                        \"Booking - intermediary Name\":\"Question7_Booking_intermediary_number\",\n",
    "                                        \"Are you going to require meeting rooms?\":\"Question8_Meeting_rooms\",\n",
    "                                        \"Do you book your events directly or through an intermediary?\":\"Question9_Events_intermediary\",\n",
    "                                        \"Events - Intermediary Name\":\"Question10_Events_intermediary_number\",\n",
    "                                        \"Could you tell us the name of the events intermediary?\":\"Question11_Events_intermediary_name\",\n",
    "                                        \"Do you accept the conditions of the GPDR?\":\"Question12_GDPR_conditions\",\n",
    "                                        \"Remarks\":\"Remarks\",\n",
    "                                        \"PID empresa\":\"PID\",\n",
    "                                        \"nombre empresa\":\"Enterprise_name\",\n",
    "                                        \"categoria A/B/C\":\"Category\",\n",
    "                                        \"terms & conditions aceptados yes/no\":\"Terms_and_condition\",\n",
    "                                        \"credentials yes/no\":\"Credentials\",\n",
    "                                        \"total revenue last year\":\"Revenue_last_year\",\n",
    "                                        \"email\":\"Email\",\n",
    "                                    })\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Hour\"] = pd.to_datetime(doc[\"Hour\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Transaction_time\"] = pd.to_datetime(doc[\"Transaction_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Contact_time\"] = pd.to_datetime(doc[\"Contact_time\"]).dt.strftime('%H:%M:%S')\n",
    "                output = doc.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_12_CAT_Calls_Codification',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 18:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_13_Guest_Experience_status UPLOADING')\n",
    "                with fs.open('trueit_external/Guest_experience_breaks/Status_Guest_Experience_breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')       \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)\n",
    "                r[\"Date\"] = pd.to_datetime(r[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_date\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_hour\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_status_date\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"End_status_hour\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_13_Guest_Experience_status',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_13_Guest_Experience_status UPLOADING')\n",
    "                with fs.open('trueit_external/Guest_experience_breaks/Status_Guest_Experience_breaks_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')       \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)\n",
    "                r[\"Date\"] = pd.to_datetime(r[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_date\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Inicio_status_hour\"] = pd.to_datetime(r[\"Inicio_status\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_status_date\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"End_status_hour\"] = pd.to_datetime(r[\"End_status\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_13_Guest_Experience_status',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 19:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_14_waiting_time UPLOADING')\n",
    "                with fs.open('trueit_external/Waiting_time/Calls_Waiting_report_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                r = doc.astype(str)\n",
    "                r[\"Fecha\"] = pd.to_datetime(r[\"Fecha\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Start_hour\"] = pd.to_datetime(r[\"Start_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_hour\"] = pd.to_datetime(r[\"End_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"Duration\"] = pd.to_datetime(r[\"Duration\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_DBR\"] = pd.to_datetime(r[\"T_DBR\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_COLA\"] = pd.to_datetime(r[\"T_COLA\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_ACW\"] = pd.to_datetime(r[\"T_ACW\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_14_waiting_time',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_14_waiting_time UPLOADING')\n",
    "                with fs.open('trueit_external/Waiting_time/Calls_Waiting_report_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                r = doc.astype(str)\n",
    "                r[\"Fecha\"] = pd.to_datetime(r[\"Fecha\"]).dt.strftime('%Y-%m-%d')\n",
    "                r[\"Start_hour\"] = pd.to_datetime(r[\"Start_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"End_hour\"] = pd.to_datetime(r[\"End_hour\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"Duration\"] = pd.to_datetime(r[\"Duration\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_DBR\"] = pd.to_datetime(r[\"T_DBR\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_COLA\"] = pd.to_datetime(r[\"T_COLA\"]).dt.strftime('%H:%M:%S')\n",
    "                r[\"T_ACW\"] = pd.to_datetime(r[\"T_ACW\"]).dt.strftime('%H:%M:%S')\n",
    "                output = r.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_14_waiting_time',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 20:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = \"0\"+str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_15_agent_session_control UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_session_control/Status_Agent_sessions_control_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                r = doc.astype(str)\n",
    "                f = r.rename(columns={\"Agent ID\":\"Agent_ID\",\n",
    "                                    \"Session Start\":\"Session_start\",\n",
    "                                    \"Session Available\":\"Session_available\",\n",
    "                                    \"Session End\":\"Session_end\",\n",
    "                                    \"Time Connected\":\"Time_connected\",\n",
    "                                    \"Time Available\":\"Time_available\",\n",
    "                                    \"Time Break\":\"Time_break\",\n",
    "                                    \"Time Visual Rest\":\"Time_visual_rest\"\n",
    "                                    })\n",
    "                f[\"Date\"] = pd.to_datetime(f[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "                f['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                f[\"Session_start\"] = pd.to_datetime(f[\"Session_start\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Session_available\"] = pd.to_datetime(f[\"Session_available\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Session_end\"] = pd.to_datetime(f[\"Session_end\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Time_connected\"] = pd.to_datetime(f[\"Time_connected\"]).dt.strftime('%H:%M:%S')\n",
    "                f[\"Time_available\"] = pd.to_datetime(f[\"Time_available\"]).dt.strftime('%H:%M:%S')\n",
    "                f[\"Time_break\"] = pd.to_datetime(f[\"Time_break\"]).dt.strftime('%H:%M:%S')\n",
    "                output = f.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.drop('GroupLevel', axis=1,inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_15_agent_session_control',project_id='nh-cro-forecast', if_exists='append')\n",
    "  \n",
    "            else:\n",
    "                Day = str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_15_agent_session_control UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_session_control/Status_Agent_sessions_control_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                r = doc.astype(str)\n",
    "                f = r.rename(columns={\"Agent ID\":\"Agent_ID\",\n",
    "                                    \"Session Start\":\"Session_start\",\n",
    "                                    \"Session Available\":\"Session_available\",\n",
    "                                    \"Session End\":\"Session_end\",\n",
    "                                    \"Time Connected\":\"Time_connected\",\n",
    "                                    \"Time Available\":\"Time_available\",\n",
    "                                    \"Time Break\":\"Time_break\",\n",
    "                                    \"Time Visual Rest\":\"Time_visual_rest\"\n",
    "                                    })\n",
    "                f[\"Date\"] = pd.to_datetime(f[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "                f['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                f[\"Session_start\"] = pd.to_datetime(f[\"Session_start\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Session_available\"] = pd.to_datetime(f[\"Session_available\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Session_end\"] = pd.to_datetime(f[\"Session_end\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                f[\"Time_connected\"] = pd.to_datetime(f[\"Time_connected\"]).dt.strftime('%H:%M:%S')\n",
    "                f[\"Time_available\"] = pd.to_datetime(f[\"Time_available\"]).dt.strftime('%H:%M:%S')\n",
    "                f[\"Time_break\"] = pd.to_datetime(f[\"Time_break\"]).dt.strftime('%H:%M:%S')\n",
    "                output = f.astype(str)\n",
    "                output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                output.drop('GroupLevel', axis=1,inplace=True)\n",
    "                output.to_gbq(destination_table='Evolution.e_15_agent_session_control',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 21:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_16_Auditorias UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Audit_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1',dtype = str)      \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)   \n",
    "                r.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)   \n",
    "                r[\"Event_Date\"] = pd.to_datetime(r[\"Event_Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Event_Hour\"] = pd.to_datetime(r[\"Event_Hour\"]).dt.strftime('%H:%M:%S') \n",
    "                r[\"Audit_Date\"] = pd.to_datetime(r[\"Audit_Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Audit_Hour\"] = pd.to_datetime(r[\"Audit_Hour\"]).dt.strftime('%H:%M:%S')   \n",
    "                r[\"Mark\"] = r[\"Mark\"].str.replace(',','.')\n",
    "                r[\"Mark_Factor\"] = r[\"Mark_Factor\"].str.replace(',','.')\n",
    "                r[\"Target\"] = r[\"Target\"].str.replace(',','.')  \n",
    "                r.to_gbq(destination_table='Evolution.e_16_Auditorias',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_16_Auditorias UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Audit_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1',dtype = str)      \n",
    "                doc = doc.iloc[0:,1:]\n",
    "                r = doc.astype(str)   \n",
    "                r.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)   \n",
    "                r[\"Event_Date\"] = pd.to_datetime(r[\"Event_Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Event_Hour\"] = pd.to_datetime(r[\"Event_Hour\"]).dt.strftime('%H:%M:%S') \n",
    "                r[\"Audit_Date\"] = pd.to_datetime(r[\"Audit_Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                r[\"Audit_Hour\"] = pd.to_datetime(r[\"Audit_Hour\"]).dt.strftime('%H:%M:%S')   \n",
    "                r[\"Mark\"] = r[\"Mark\"].str.replace(',','.')\n",
    "                r[\"Mark_Factor\"] = r[\"Mark_Factor\"].str.replace(',','.')\n",
    "                r[\"Target\"] = r[\"Target\"].str.replace(',','.')  \n",
    "                r.to_gbq(destination_table='Evolution.e_16_Auditorias',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 22:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agents_sessions UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_Sessions/Agents_Sessions_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                doc.columns = ['Date','Service','Agent','Agent_SAP','Agent_ID','Worktop','Begin_session_raw','Available_session_raw','End_session_raw','Session_duration','n_breaks','Break_reason','Break_ID','Break_duration']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Begin_session_date\"] = pd.to_datetime(doc[\"Begin_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Begin_session_hour\"] = pd.to_datetime(doc[\"Begin_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Available_session_date\"] = pd.to_datetime(doc[\"Available_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Available_session_hour\"] = pd.to_datetime(doc[\"Available_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"End_session_date\"] = pd.to_datetime(doc[\"End_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"End_session_hour\"] = pd.to_datetime(doc[\"End_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agents_sessions\"] = pd.to_datetime(doc[\"Session_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Break_duration\"] = pd.to_datetime(doc[\"Break_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Session_duration\"] = pd.to_datetime(doc[\"Session_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                Output = doc.astype(str)\n",
    "                Output = Output.iloc[:,[0,1,2,3,4,5,6,14,15,7,16,17,8,18,19,9,10,11,12,13]]\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_SAP':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Worktop':object,\n",
    "                                'Begin_session_raw':object,\n",
    "                                'Begin_session_date':object,\n",
    "                                'Begin_session_hour':object,\n",
    "                                'Available_session_raw':object,\n",
    "                                'Available_session_date':object,\n",
    "                                'Available_session_hour':object,\n",
    "                                'End_session_raw':object,\n",
    "                                'End_session_date':object,\n",
    "                                'End_session_hour':object,\n",
    "                                'Session_duration':object,\n",
    "                                'n_breaks':object,\n",
    "                                'Break_reason':object,\n",
    "                                'Break_ID':object,\n",
    "                                'Break_duration':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Agents_sessions',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agents_sessions UPLOADING')\n",
    "                with fs.open('trueit_external/Agent_Sessions/Agents_Sessions_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                doc.columns = ['Date','Service','Agent','Agent_SAP','Agent_ID','Worktop','Begin_session_raw','Available_session_raw','End_session_raw','Session_duration','n_breaks','Break_reason','Break_ID','Break_duration']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Begin_session_date\"] = pd.to_datetime(doc[\"Begin_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Begin_session_hour\"] = pd.to_datetime(doc[\"Begin_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Available_session_date\"] = pd.to_datetime(doc[\"Available_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Available_session_hour\"] = pd.to_datetime(doc[\"Available_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"End_session_date\"] = pd.to_datetime(doc[\"End_session_raw\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"End_session_hour\"] = pd.to_datetime(doc[\"End_session_raw\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Agents_sessions\"] = pd.to_datetime(doc[\"Session_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Break_duration\"] = pd.to_datetime(doc[\"Break_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Session_duration\"] = pd.to_datetime(doc[\"Session_duration\"]).dt.strftime('%H:%M:%S')\n",
    "                Output = doc.astype(str)\n",
    "                Output = Output.iloc[:,[0,1,2,3,4,5,6,14,15,7,16,17,8,18,19,9,10,11,12,13]]\n",
    "                convert_dict = {'Date':object,\n",
    "                                'Service':object,\n",
    "                                'Agent':object,\n",
    "                                'Agent_SAP':object,\n",
    "                                'Agent_ID':object,\n",
    "                                'Worktop':object,\n",
    "                                'Begin_session_raw':object,\n",
    "                                'Begin_session_date':object,\n",
    "                                'Begin_session_hour':object,\n",
    "                                'Available_session_raw':object,\n",
    "                                'Available_session_date':object,\n",
    "                                'Available_session_hour':object,\n",
    "                                'End_session_raw':object,\n",
    "                                'End_session_date':object,\n",
    "                                'End_session_hour':object,\n",
    "                                'Session_duration':object,\n",
    "                                'n_breaks':object,\n",
    "                                'Break_reason':object,\n",
    "                                'Break_ID':object,\n",
    "                                'Break_duration':object} \n",
    "                Call_db = Output.astype(convert_dict)\n",
    "                Call_db = Call_db.astype(str)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Agents_sessions',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 23:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_Hotel_Distribution UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Hotel_Distribution/Calls_Hotel_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                doc.drop('grouplevel', axis=1, inplace=True)\n",
    "                column = ['Date',\n",
    "                        'Service',\n",
    "                        'Hotel_name',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Slot',\n",
    "                        'Incoming_calls',\n",
    "                        'Answered',\n",
    "                        'Non_answered',\n",
    "                        'Abandoned',\n",
    "                        'Abandoned_less_10s',\n",
    "                        'Out_service_hours']\n",
    "                doc['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                doc.columns = column\n",
    "                doc = doc.astype(str)\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_Hotel_Distribution',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_Hotel_Distribution UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Hotel_Distribution/Calls_Hotel_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')      \n",
    "                doc.drop('grouplevel', axis=1, inplace=True)\n",
    "                column = ['Date',\n",
    "                        'Service',\n",
    "                        'Hotel_name',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Slot',\n",
    "                        'Incoming_calls',\n",
    "                        'Answered',\n",
    "                        'Non_answered',\n",
    "                        'Abandoned',\n",
    "                        'Abandoned_less_10s',\n",
    "                        'Out_service_hours']\n",
    "                doc['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                doc.columns = column\n",
    "                doc = doc.astype(str)\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_Hotel_Distribution',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 24:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = \"0\"+str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_out_of_time UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_out_of_Time/Call_out_of_time_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:-1]\n",
    "                doc['Fecha'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                column = ['Date',\n",
    "                        'Service',\n",
    "                        'Campaign',\n",
    "                        'ID_Campaign',\n",
    "                        'LANGUAGE',\n",
    "                        'IVR_OPTION',\n",
    "                        'Time_Slot',\n",
    "                        'Total_Calls',\n",
    "                        'Abandoned_Calls_less_10_secs',\n",
    "                        'Abandoned_Calls_more_10_secs',\n",
    "                        'Transfer_Calls',\n",
    "                        'Calls_to_answering_machine']      \n",
    "                doc.columns = column           \n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)          \n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)           \n",
    "                doc.to_gbq(destination_table='Evolution.Calls_out_of_time',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                Day = \"0\"+str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_out_of_time UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_out_of_Time/Call_out_of_time_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:-1]\n",
    "                doc['Fecha'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                column = ['Date',\n",
    "                        'Service',\n",
    "                        'Campaign',\n",
    "                        'ID_Campaign',\n",
    "                        'LANGUAGE',\n",
    "                        'IVR_OPTION',\n",
    "                        'Time_Slot',\n",
    "                        'Total_Calls',\n",
    "                        'Abandoned_Calls_less_10_secs',\n",
    "                        'Abandoned_Calls_more_10_secs',\n",
    "                        'Transfer_Calls',\n",
    "                        'Calls_to_answering_machine']      \n",
    "                doc.columns = column           \n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)          \n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)           \n",
    "                doc.to_gbq(destination_table='Evolution.Calls_out_of_time',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 25:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = \"0\"+str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('IVR UPLOADING')\n",
    "                with fs.open('trueit_external/IVR_Distribution/IVR_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                column = ['Date', \n",
    "                        'Service',\n",
    "                        'Campaign',\n",
    "                        'ID',\n",
    "                        'LANGUAGE',\n",
    "                        'Time_Zone',\n",
    "                        'IVR_OPTION',\n",
    "                        'Incoming_Calls',\n",
    "                        'Abandoned',\n",
    "                        'Abandoned_Before_Queue',\n",
    "                        'Transfered_Calls']      \n",
    "                doc.columns = column         \n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)           \n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.IVR',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                Day_1 = int(Day)-1\n",
    "                Day_1 = str(Day_1)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('IVR UPLOADING')\n",
    "                with fs.open('trueit_external/IVR_Distribution/IVR_Distribution_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc['Date'] = Year+\"-\"+Month+\"-\"+Day_1\n",
    "                column = ['Date', \n",
    "                        'Service',\n",
    "                        'Campaign',\n",
    "                        'ID',\n",
    "                        'LANGUAGE',\n",
    "                        'Time_Zone',\n",
    "                        'IVR_OPTION',\n",
    "                        'Incoming_Calls',\n",
    "                        'Abandoned',\n",
    "                        'Abandoned_Before_Queue',\n",
    "                        'Transfered_Calls']      \n",
    "                doc.columns = column         \n",
    "                doc = doc.astype(object)\n",
    "                doc = doc.astype(str)           \n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.IVR',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 26:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Rejected_calls UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Rejected/Reporte_Llamadas_rechazadas_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Fecha',\n",
    "                            'Service',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Transaction_ID',\n",
    "                            'Contact_ID',\n",
    "                            'Type',\n",
    "                            'Time',\n",
    "                            'Next_pause',\n",
    "                            'Time_until_pause']\n",
    "                doc[\"Fecha\"] = pd.to_datetime(doc[\"Fecha\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Time\"] = pd.to_datetime(doc[\"Time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Next_pause_date\"] = pd.to_datetime(doc[\"Next_pause\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Next_pause_hour\"] = pd.to_datetime(doc[\"Next_pause\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_until_pause\"] = pd.to_datetime(doc[\"Time_until_pause\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Fecha', \n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Transaction_ID',\n",
    "                        'Contact_ID',\n",
    "                        'Type',\n",
    "                        'Time',\n",
    "                        'Next_pause_date',\n",
    "                        'Next_pause_hour',\n",
    "                        'Time_until_pause']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Rejected_calls',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Rejected_calls UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Rejected/Reporte_Llamadas_rechazadas_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Fecha',\n",
    "                            'Service',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Transaction_ID',\n",
    "                            'Contact_ID',\n",
    "                            'Type',\n",
    "                            'Time',\n",
    "                            'Next_pause',\n",
    "                            'Time_until_pause']\n",
    "                doc[\"Fecha\"] = pd.to_datetime(doc[\"Fecha\"], format=('%d/%m/%Y')).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Time\"] = pd.to_datetime(doc[\"Time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Next_pause_date\"] = pd.to_datetime(doc[\"Next_pause\"]).dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Next_pause_hour\"] = pd.to_datetime(doc[\"Next_pause\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Time_until_pause\"] = pd.to_datetime(doc[\"Time_until_pause\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Fecha', \n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Transaction_ID',\n",
    "                        'Contact_ID',\n",
    "                        'Type',\n",
    "                        'Time',\n",
    "                        'Next_pause_date',\n",
    "                        'Next_pause_hour',\n",
    "                        'Time_until_pause']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Rejected_calls',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 27:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue_time_slot UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign_Slot/CDRAgente_Campanya_Tramos_Tarde_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Service', \n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_zone',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Call_time_in',\n",
    "                            'Call_time_out',\n",
    "                            'Call_total_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Call_time_in\"] = pd.to_datetime(doc[\"Call_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_time_out\"] = pd.to_datetime(doc[\"Call_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_total_time\"] = pd.to_datetime(doc[\"Call_total_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Service', \n",
    "                        'Date',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Time_zone',\n",
    "                        'Calls_in',\n",
    "                        'Calls_out',\n",
    "                        'Call_time_in',\n",
    "                        'Call_time_out',\n",
    "                        'Call_total_time']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_per_queue_time_slot',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue_time_slot UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign_Slot/CDRAgente_Campanya_Tramos_Tarde_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Service', \n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_zone',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Call_time_in',\n",
    "                            'Call_time_out',\n",
    "                            'Call_total_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Call_time_in\"] = pd.to_datetime(doc[\"Call_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_time_out\"] = pd.to_datetime(doc[\"Call_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_total_time\"] = pd.to_datetime(doc[\"Call_total_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Service', \n",
    "                        'Date',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Time_zone',\n",
    "                        'Calls_in',\n",
    "                        'Calls_out',\n",
    "                        'Call_time_in',\n",
    "                        'Call_time_out',\n",
    "                        'Call_total_time']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_per_queue_time_slot',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 28:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue_time_slot UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign_Slot/CDRAgente_Campanya_Tramos_Maniana_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Service', \n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_zone',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Call_time_in',\n",
    "                            'Call_time_out',\n",
    "                            'Call_total_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Call_time_in\"] = pd.to_datetime(doc[\"Call_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_time_out\"] = pd.to_datetime(doc[\"Call_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_total_time\"] = pd.to_datetime(doc[\"Call_total_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Service', \n",
    "                        'Date',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Time_zone',\n",
    "                        'Calls_in',\n",
    "                        'Calls_out',\n",
    "                        'Call_time_in',\n",
    "                        'Call_time_out',\n",
    "                        'Call_total_time']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_per_queue_time_slot',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Calls_per_queue_time_slot UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_By_Agent_Campaign_Slot/CDRAgente_Campanya_Tramos_Maniana_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,1:]\n",
    "                doc = doc.astype(str)\n",
    "                doc.columns=['Service', \n",
    "                            'Date',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_ID',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Time_zone',\n",
    "                            'Calls_in',\n",
    "                            'Calls_out',\n",
    "                            'Call_time_in',\n",
    "                            'Call_time_out',\n",
    "                            'Call_total_time']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"],format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc[\"Call_time_in\"] = pd.to_datetime(doc[\"Call_time_in\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_time_out\"] = pd.to_datetime(doc[\"Call_time_out\"]).dt.strftime('%H:%M:%S')\n",
    "                doc[\"Call_total_time\"] = pd.to_datetime(doc[\"Call_total_time\"]).dt.strftime('%H:%M:%S')\n",
    "                doc = doc[['Service', \n",
    "                        'Date',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_ID',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Time_zone',\n",
    "                        'Calls_in',\n",
    "                        'Calls_out',\n",
    "                        'Call_time_in',\n",
    "                        'Call_time_out',\n",
    "                        'Call_total_time']]\n",
    "\n",
    "                doc.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                doc.to_gbq(destination_table='Evolution.Calls_per_queue_time_slot',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 29:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Codifications UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications/Call_Codification_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')           \n",
    "                doc.drop('grouplevel', axis=1, inplace=True)\n",
    "                doc.columns = ['Date',\n",
    "                            'Service',\n",
    "                            'Transaction_ID',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Inbound_outbound',\n",
    "                            'State',\n",
    "                            'Client_type',\n",
    "                            'Hotel_name',\n",
    "                            'Reason_of_the_call',\n",
    "                            'Reason_closure',\n",
    "                            'Closure',\n",
    "                            'Number_handled',\n",
    "                            'Codification_time',\n",
    "                            'Time_call_onhold',\n",
    "                            'Time_call_active',\n",
    "                            'Type_closure']  \n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(str)\n",
    "                doc = doc[['Date',\n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Transaction_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_number',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Inbound_outbound',\n",
    "                        'State',\n",
    "                        'Client_type',\n",
    "                        'Hotel_name',\n",
    "                        'Reason_of_the_call',\n",
    "                        'Reason_closure',\n",
    "                        'Closure',\n",
    "                        'Number_handled',\n",
    "                        'Codification_time']]     \n",
    "                Call_db = doc.astype(object)  \n",
    "                Call_db['Number_handled'] = Call_db['Number_handled'].astype(int)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Codifications',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Codifications UPLOADING')\n",
    "                with fs.open('trueit_external/Calls_Codifications/Call_Codification_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')           \n",
    "                doc.drop('grouplevel', axis=1, inplace=True)\n",
    "                doc.columns = ['Date',\n",
    "                            'Service',\n",
    "                            'Transaction_ID',\n",
    "                            'Agent',\n",
    "                            'Agent_ID',\n",
    "                            'Campaign',\n",
    "                            'Campaign_number',\n",
    "                            'Language',\n",
    "                            'IVR_option',\n",
    "                            'Inbound_outbound',\n",
    "                            'State',\n",
    "                            'Client_type',\n",
    "                            'Hotel_name',\n",
    "                            'Reason_of_the_call',\n",
    "                            'Reason_closure',\n",
    "                            'Closure',\n",
    "                            'Number_handled',\n",
    "                            'Codification_time',\n",
    "                            'Time_call_onhold',\n",
    "                            'Time_call_active',\n",
    "                            'Type_closure']  \n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(str)\n",
    "                doc = doc[['Date',\n",
    "                        'Service',\n",
    "                        'Agent',\n",
    "                        'Agent_ID',\n",
    "                        'Transaction_ID',\n",
    "                        'Campaign',\n",
    "                        'Campaign_number',\n",
    "                        'Language',\n",
    "                        'IVR_option',\n",
    "                        'Inbound_outbound',\n",
    "                        'State',\n",
    "                        'Client_type',\n",
    "                        'Hotel_name',\n",
    "                        'Reason_of_the_call',\n",
    "                        'Reason_closure',\n",
    "                        'Closure',\n",
    "                        'Number_handled',\n",
    "                        'Codification_time']]     \n",
    "                Call_db = doc.astype(object)  \n",
    "                Call_db['Number_handled'] = Call_db['Number_handled'].astype(int)\n",
    "                Call_db.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None], inplace=True)\n",
    "                Call_db.to_gbq(destination_table='Evolution.Codifications',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 30:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agent_Nomenclature UPLOADING')\n",
    "                with fs.open('trueit_external/User_Nomenclatures/Nomenclaturas_Usuarios_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,0:]\n",
    "                doc.columns = ['Date','Service', 'Agent', 'Agent_ID']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(str)\n",
    "                doc.to_gbq(destination_table='Evolution.Agent_Nomenclature',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('Agent_Nomenclature UPLOADING')\n",
    "                with fs.open('trueit_external/User_Nomenclatures/Nomenclaturas_Usuarios_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[1:,0:]\n",
    "                doc.columns = ['Date','Service', 'Agent', 'Agent_ID']\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                doc = doc.astype(str)\n",
    "                doc.to_gbq(destination_table='Evolution.Agent_Nomenclature',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 31:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_17_Facturacion_logins UPLOADING')\n",
    "                with fs.open('trueit_external/Facturacion_current_logins/Concurrent_logins_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['grouplevel',\n",
    "                            'Date',\n",
    "                            'Service',\n",
    "                            'Total_logins',\n",
    "                            'Number_concurrente',\n",
    "                            'Max_concurrente']\n",
    "\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                Output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                Output.to_gbq(destination_table='Evolution.e_17_Facturacion_logins',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_17_Facturacion_logins UPLOADING')\n",
    "                with fs.open('trueit_external/Facturacion_current_logins/Concurrent_logins_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc.columns=['grouplevel',\n",
    "                            'Date',\n",
    "                            'Service',\n",
    "                            'Total_logins',\n",
    "                            'Number_concurrente',\n",
    "                            'Max_concurrente']\n",
    "\n",
    "                doc[\"Date\"] = pd.to_datetime(doc[\"Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                Output = doc.astype(str)\n",
    "                Output.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                Output.to_gbq(destination_table='Evolution.e_17_Facturacion_logins',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 32:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('SLA_completed_Hotel_pdf UPLOADING')\n",
    "                with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[:,1:]\n",
    "                doc.columns=['Service',\n",
    "                            'Entry_date',\n",
    "                            'Entry_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID',\n",
    "                            'Alias',\n",
    "                            'Agent_distributed',\n",
    "                            'Distributed_date',\n",
    "                            'Distributed_hour',\n",
    "                            'Queue',\n",
    "                            'Completed',\n",
    "                            'Agent_completed',\n",
    "                            'Completed_date',\n",
    "                            'Completed_hour',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'due_on',\n",
    "                            'From_mail',\n",
    "                            'IN_OUT',\n",
    "                            'Total_time',\n",
    "                            'Match',\n",
    "                            'Match_level',\n",
    "                            'Hotel',\n",
    "                            'Country',\n",
    "                            'City',\n",
    "                            'Hotel_ID']\n",
    "                raw = doc.astype(str)\n",
    "                raw = raw.loc[:,['Service',\n",
    "                        'Entry_date',\n",
    "                        'Entry_hour',\n",
    "                        'Activity_ID',\n",
    "                        'Case_ID',\n",
    "                        'Alias',\n",
    "                        'Agent_distributed',\n",
    "                        'Distributed_date',\n",
    "                        'Distributed_hour',\n",
    "                        'Queue',\n",
    "                        'Completed',\n",
    "                        'Agent_completed',\n",
    "                        'Completed_date',\n",
    "                        'Completed_hour',\n",
    "                        'Type',\n",
    "                        'Subtype',\n",
    "                        'due_on',\n",
    "                        'From_mail',\n",
    "                        'IN_OUT',\n",
    "                        'Total_time',\n",
    "                        'Match',\n",
    "                        'Match_level',\n",
    "                        'Country',\n",
    "                        'City',\n",
    "                        'Hotel',\n",
    "                        'Hotel_ID']]\n",
    "                raw = doc.astype(str)\n",
    "                raw.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                raw[\"Entry_date\"] = pd.to_datetime(raw[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw[\"Completed_date\"] = pd.to_datetime(raw[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw[\"Distributed_date\"] = pd.to_datetime(raw[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw.to_gbq(destination_table='Evolution.SLA_completed_Hotel_pdf',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('SLA_completed_Hotel_pdf UPLOADING')\n",
    "                with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+Year+Month+Day+'.csv') as f:\n",
    "                    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "                doc = doc.iloc[:,1:]\n",
    "                doc.columns=['Service',\n",
    "                            'Entry_date',\n",
    "                            'Entry_hour',\n",
    "                            'Activity_ID',\n",
    "                            'Case_ID',\n",
    "                            'Alias',\n",
    "                            'Agent_distributed',\n",
    "                            'Distributed_date',\n",
    "                            'Distributed_hour',\n",
    "                            'Queue',\n",
    "                            'Completed',\n",
    "                            'Agent_completed',\n",
    "                            'Completed_date',\n",
    "                            'Completed_hour',\n",
    "                            'Type',\n",
    "                            'Subtype',\n",
    "                            'due_on',\n",
    "                            'From_mail',\n",
    "                            'IN_OUT',\n",
    "                            'Total_time',\n",
    "                            'Match',\n",
    "                            'Match_level',\n",
    "                            'Hotel',\n",
    "                            'Country',\n",
    "                            'City',\n",
    "                            'Hotel_ID']\n",
    "                raw = doc.astype(str)\n",
    "                raw = raw.loc[:,['Service',\n",
    "                        'Entry_date',\n",
    "                        'Entry_hour',\n",
    "                        'Activity_ID',\n",
    "                        'Case_ID',\n",
    "                        'Alias',\n",
    "                        'Agent_distributed',\n",
    "                        'Distributed_date',\n",
    "                        'Distributed_hour',\n",
    "                        'Queue',\n",
    "                        'Completed',\n",
    "                        'Agent_completed',\n",
    "                        'Completed_date',\n",
    "                        'Completed_hour',\n",
    "                        'Type',\n",
    "                        'Subtype',\n",
    "                        'due_on',\n",
    "                        'From_mail',\n",
    "                        'IN_OUT',\n",
    "                        'Total_time',\n",
    "                        'Match',\n",
    "                        'Match_level',\n",
    "                        'Country',\n",
    "                        'City',\n",
    "                        'Hotel',\n",
    "                        'Hotel_ID']]\n",
    "                raw = doc.astype(str)\n",
    "                raw.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "                raw[\"Entry_date\"] = pd.to_datetime(raw[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw[\"Completed_date\"] = pd.to_datetime(raw[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw[\"Distributed_date\"] = pd.to_datetime(raw[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                raw.to_gbq(destination_table='Evolution.SLA_completed_Hotel_pdf',project_id='nh-cro-forecast', if_exists='append')\n",
    "elif Query_number == 33:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_301_GEM_Audits UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Audit_GEM_'+Year+Month+Day+'.csv') as f:\n",
    "                    df_audits= pd.read_csv(f,delimiter=\";\", encoding='latin-1', on_bad_lines='skip', dtype='str')\n",
    "\n",
    "                df_audits.drop('GroupLevel', inplace=True, axis=1)\n",
    "                df_audits['Event_Date'] = pd.to_datetime(df_audits[\"Event_Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                df_audits['Audit_Date'] = pd.to_datetime(df_audits[\"Audit_Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "                df_audits.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "\n",
    "                df_audits.to_gbq(destination_table='Evolution.e_301_GEM_Audits',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('e_301_GEM_Audits UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Audit_GEM_'+Year+Month+Day+'.csv') as f:\n",
    "                    df_audits= pd.read_csv(f,delimiter=\";\", encoding='latin-1', on_bad_lines='skip', dtype='str')\n",
    "\n",
    "                df_audits.drop('GroupLevel', inplace=True, axis=1)\n",
    "                df_audits['Event_Date'] = pd.to_datetime(df_audits[\"Event_Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                df_audits['Audit_Date'] = pd.to_datetime(df_audits[\"Audit_Date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "                df_audits.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "\n",
    "                df_audits.to_gbq(destination_table='Evolution.e_301_GEM_Audits',project_id='nh-cro-forecast', if_exists='append')\n",
    "else:\n",
    "        for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "            if i <10: \n",
    "                Day = \"0\"+str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('QA_Lista_Admin UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Reporte_QA_Lista_Admin_'+Year+Month+Day+'.csv') as f:\n",
    "                    df_audits_coord= pd.read_csv(f,delimiter=\";\", encoding='latin-1', on_bad_lines='skip', dtype='str')\n",
    "\n",
    "                df_audits_coord.drop('GroupLevel',axis=1,inplace=True)\n",
    "                df_audits_coord['Fecha'] = pd.to_datetime(df_audits_coord[\"Fecha\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                df_audits_coord.to_gbq(destination_table='Evolution.QA_Lista_Admin',project_id='nh-cro-forecast', if_exists='append')\n",
    "            else:\n",
    "                Day = str(i)\n",
    "                print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "                print('QA_Lista_Admin UPLOADING')\n",
    "                with fs.open('trueit_external/Auditorias/Reporte_QA_Lista_Admin_'+Year+Month+Day+'.csv') as f:\n",
    "                    df_audits_coord= pd.read_csv(f,delimiter=\";\", encoding='latin-1', on_bad_lines='skip', dtype='str')\n",
    "\n",
    "                df_audits_coord.drop('GroupLevel',axis=1,inplace=True)\n",
    "                df_audits_coord['Fecha'] = pd.to_datetime(df_audits_coord[\"Fecha\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "                df_audits_coord.to_gbq(destination_table='Evolution.QA_Lista_Admin',project_id='nh-cro-forecast', if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORRADOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Año:  2024\n",
      "Mes:  05\n",
      "Día inicio: 14\n",
      "Día fin: 23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "from pandas.io import gbq\n",
    "from datetime import date, timedelta, datetime\n",
    "import ctypes\n",
    "import chardet\n",
    "import gcsfs\n",
    "from io import StringIO\n",
    "import google.auth\n",
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import logging\n",
    "import os\n",
    "import win32com.client\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "# Credentials to extract data from the Bucket\n",
    "fs = gcsfs.GCSFileSystem(project='nh-cro-forecast', token = r'C:\\Users\\ej.garcia\\OneDrive - Minor Hotels Europe & Americas\\Escritorio\\nh-cro-forecast-ec5c044f54cf.json')\n",
    "\n",
    "#DEFINIMOS AÑO, MES E INICIO DE DIA Y FINAL DE DIA\n",
    "year = \"2024\"\n",
    "print('Año: ',year)\n",
    "mes = \"05\"\n",
    "print(\"Mes: \",mes)\n",
    "\n",
    "inicio_dia = \"14\"\n",
    "print(\"Día inicio:\", inicio_dia)\n",
    "\n",
    "fin_dia = \"23\"\n",
    "print(\"Día fin:\", fin_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+year+mes+inicio_dia+'.csv') as f:\n",
    "    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouplevel</th>\n",
       "      <th>Service</th>\n",
       "      <th>ENTRY_DATE</th>\n",
       "      <th>ENTRY_HOUR</th>\n",
       "      <th>ACTIVITY_ID</th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>Alias</th>\n",
       "      <th>AGENT_DISTRIBUTED</th>\n",
       "      <th>DISTRIBUTED_DATE</th>\n",
       "      <th>DISTRIBUTED_HOUR</th>\n",
       "      <th>...</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>due_on</th>\n",
       "      <th>from_mail</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>REAL_TIME_ACTIVITY</th>\n",
       "      <th>MATCH</th>\n",
       "      <th>MATCH LEVEL</th>\n",
       "      <th>PAIS</th>\n",
       "      <th>CIUDAD</th>\n",
       "      <th>HOTEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:31:11</td>\n",
       "      <td>122175699</td>\n",
       "      <td>109038051</td>\n",
       "      <td>EDS.RESERVIERUNGEN@NH-HOTELS.COM</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:37:26</td>\n",
       "      <td>...</td>\n",
       "      <td>Finished by system</td>\n",
       "      <td>15/05/2024 01:31:11</td>\n",
       "      <td>CONNECTIVITY_SUPPORT@NH-HOTELS.COM</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>at09.atter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AUSTRIA</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NH Collection Wien Zentrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:22:45</td>\n",
       "      <td>122175656</td>\n",
       "      <td>109038230</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:23</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 01:22:45</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:11</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:34:37</td>\n",
       "      <td>122175417</td>\n",
       "      <td>109038252</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:34:37</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:01:33</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:39:28</td>\n",
       "      <td>122175448</td>\n",
       "      <td>109038264</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:39:28</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:46:50</td>\n",
       "      <td>122175485</td>\n",
       "      <td>109038284</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:41:38</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:46:50</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>nh madrid zurbano</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NH Zurbano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grouplevel Service  ENTRY_DATE ENTRY_HOUR  ACTIVITY_ID    CASE_ID  \\\n",
       "0           0     CRO  12/05/2024   23:31:11    122175699  109038051   \n",
       "1           0     CRO  12/05/2024   23:22:45    122175656  109038230   \n",
       "2           0     CRO  12/05/2024   22:34:37    122175417  109038252   \n",
       "3           0     CRO  12/05/2024   22:39:28    122175448  109038264   \n",
       "4           0     CRO  12/05/2024   22:46:50    122175485  109038284   \n",
       "\n",
       "                              Alias AGENT_DISTRIBUTED DISTRIBUTED_DATE  \\\n",
       "0  EDS.RESERVIERUNGEN@NH-HOTELS.COM     SYSTEM SYSTEM       12/05/2024   \n",
       "1        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "2        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "3        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "4        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "\n",
       "  DISTRIBUTED_HOUR  ...             Subtype               due_on  \\\n",
       "0         23:37:26  ...  Finished by system  15/05/2024 01:31:11   \n",
       "1         23:38:23  ...  Finish Transaction  15/05/2024 01:22:45   \n",
       "2         23:38:24  ...  Finish Transaction  15/05/2024 00:34:37   \n",
       "3         23:38:24  ...  Finish Transaction  15/05/2024 00:39:28   \n",
       "4         23:41:38  ...  Finish Transaction  15/05/2024 00:46:50   \n",
       "\n",
       "                            from_mail DIRECTION REAL_TIME_ACTIVITY  \\\n",
       "0  CONNECTIVITY_SUPPORT@NH-HOTELS.COM        IN           00:00:00   \n",
       "1                   discovery@gha.com        IN           00:02:11   \n",
       "2                   discovery@gha.com        IN           00:01:33   \n",
       "3                   discovery@gha.com        IN           00:02:17   \n",
       "4                   discovery@gha.com        IN           00:00:00   \n",
       "\n",
       "               MATCH MATCH LEVEL     PAIS  CIUDAD                       HOTEL  \n",
       "0         at09.atter         2.0  AUSTRIA  Vienna  NH Collection Wien Zentrum  \n",
       "1    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "2    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "3    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "4  nh madrid zurbano         3.0    SPAIN  Madrid                  NH Zurbano  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.iloc[:,1:]\n",
    "doc.columns=['Service',\n",
    "            'Entry_date',\n",
    "            'Entry_hour',\n",
    "            'Activity_ID',\n",
    "            'Case_ID',\n",
    "            'Alias',\n",
    "            'Agent_distributed',\n",
    "            'Distributed_date',\n",
    "            'Distributed_hour',\n",
    "            'Queue',\n",
    "            'Completed',\n",
    "            'Agent_completed',\n",
    "            'Completed_date',\n",
    "            'Completed_hour',\n",
    "            'Type',\n",
    "            'Subtype',\n",
    "            'due_on',\n",
    "            'From_mail',\n",
    "            'IN_OUT',\n",
    "            'Total_time',\n",
    "            'Match',\n",
    "            'Match_level',\n",
    "            'Country',\n",
    "            'City',\n",
    "            'Hotel'\n",
    "            # 'Hotel_Id'\n",
    "            ]\n",
    "# doc.insert(20,'Match','KKKKK')\n",
    "doc.insert(25,'Hotel_Id','')\n",
    "raw = doc.astype(str)\n",
    "raw = raw.loc[:,['Service',\n",
    "        'Entry_date',\n",
    "        'Entry_hour',\n",
    "        'Activity_ID',\n",
    "        'Case_ID',\n",
    "        'Alias',\n",
    "        'Agent_distributed',\n",
    "        'Distributed_date',\n",
    "        'Distributed_hour',\n",
    "        'Queue',\n",
    "        'Completed',\n",
    "        'Agent_completed',\n",
    "        'Completed_date',\n",
    "        'Completed_hour',\n",
    "        'Type',\n",
    "        'Subtype',\n",
    "        'due_on',\n",
    "        'From_mail',\n",
    "        'IN_OUT',\n",
    "        'Total_time',\n",
    "        'Match',\n",
    "        'Match_level',\n",
    "        'Country',\n",
    "        'City',\n",
    "        'Hotel',\n",
    "        'Hotel_Id'\n",
    "        ]]\n",
    "raw.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "raw[\"Entry_date\"] = pd.to_datetime(raw[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "raw[\"Completed_date\"] = pd.to_datetime(raw[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "raw[\"Distributed_date\"] = pd.to_datetime(raw[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service</th>\n",
       "      <th>Entry_date</th>\n",
       "      <th>Entry_hour</th>\n",
       "      <th>Activity_ID</th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>Alias</th>\n",
       "      <th>Agent_distributed</th>\n",
       "      <th>Distributed_date</th>\n",
       "      <th>Distributed_hour</th>\n",
       "      <th>Queue</th>\n",
       "      <th>...</th>\n",
       "      <th>due_on</th>\n",
       "      <th>From_mail</th>\n",
       "      <th>IN_OUT</th>\n",
       "      <th>Total_time</th>\n",
       "      <th>Match</th>\n",
       "      <th>Match_level</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Hotel_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRO</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:31:11</td>\n",
       "      <td>122175699</td>\n",
       "      <td>109038051</td>\n",
       "      <td>EDS.RESERVIERUNGEN@NH-HOTELS.COM</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:37:26</td>\n",
       "      <td>EMA Failover Connectivity</td>\n",
       "      <td>...</td>\n",
       "      <td>15/05/2024 01:31:11</td>\n",
       "      <td>CONNECTIVITY_SUPPORT@NH-HOTELS.COM</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>at09.atter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AUSTRIA</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NH Collection Wien Zentrum</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRO</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:22:45</td>\n",
       "      <td>122175656</td>\n",
       "      <td>109038230</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:38:23</td>\n",
       "      <td>EMA TPW GHA</td>\n",
       "      <td>...</td>\n",
       "      <td>15/05/2024 01:22:45</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:11</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRO</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>22:34:37</td>\n",
       "      <td>122175417</td>\n",
       "      <td>109038252</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>EMA TPW GHA</td>\n",
       "      <td>...</td>\n",
       "      <td>15/05/2024 00:34:37</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:01:33</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRO</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>22:39:28</td>\n",
       "      <td>122175448</td>\n",
       "      <td>109038264</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>EMA TPW GHA</td>\n",
       "      <td>...</td>\n",
       "      <td>15/05/2024 00:39:28</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRO</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>22:46:50</td>\n",
       "      <td>122175485</td>\n",
       "      <td>109038284</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>23:41:38</td>\n",
       "      <td>EMA TPW GHA</td>\n",
       "      <td>...</td>\n",
       "      <td>15/05/2024 00:46:50</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>nh madrid zurbano</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NH Zurbano</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Service  Entry_date Entry_hour Activity_ID    Case_ID  \\\n",
       "0     CRO  2024-05-12   23:31:11   122175699  109038051   \n",
       "1     CRO  2024-05-12   23:22:45   122175656  109038230   \n",
       "2     CRO  2024-05-12   22:34:37   122175417  109038252   \n",
       "3     CRO  2024-05-12   22:39:28   122175448  109038264   \n",
       "4     CRO  2024-05-12   22:46:50   122175485  109038284   \n",
       "\n",
       "                              Alias Agent_distributed Distributed_date  \\\n",
       "0  EDS.RESERVIERUNGEN@NH-HOTELS.COM     SYSTEM SYSTEM       2024-05-12   \n",
       "1        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       2024-05-12   \n",
       "2        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       2024-05-12   \n",
       "3        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       2024-05-12   \n",
       "4        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       2024-05-12   \n",
       "\n",
       "  Distributed_hour                      Queue  ...               due_on  \\\n",
       "0         23:37:26  EMA Failover Connectivity  ...  15/05/2024 01:31:11   \n",
       "1         23:38:23                EMA TPW GHA  ...  15/05/2024 01:22:45   \n",
       "2         23:38:24                EMA TPW GHA  ...  15/05/2024 00:34:37   \n",
       "3         23:38:24                EMA TPW GHA  ...  15/05/2024 00:39:28   \n",
       "4         23:41:38                EMA TPW GHA  ...  15/05/2024 00:46:50   \n",
       "\n",
       "                            From_mail IN_OUT Total_time              Match  \\\n",
       "0  CONNECTIVITY_SUPPORT@NH-HOTELS.COM     IN   00:00:00         at09.atter   \n",
       "1                   discovery@gha.com     IN   00:02:11    nh lyon airport   \n",
       "2                   discovery@gha.com     IN   00:01:33    nh lyon airport   \n",
       "3                   discovery@gha.com     IN   00:02:17    nh lyon airport   \n",
       "4                   discovery@gha.com     IN   00:00:00  nh madrid zurbano   \n",
       "\n",
       "  Match_level  Country    City                       Hotel Hotel_Id  \n",
       "0         2.0  AUSTRIA  Vienna  NH Collection Wien Zentrum           \n",
       "1         3.0   FRANCE    Lyon             NH Lyon Airport           \n",
       "2         3.0   FRANCE    Lyon             NH Lyon Airport           \n",
       "3         3.0   FRANCE    Lyon             NH Lyon Airport           \n",
       "4         3.0    SPAIN  Madrid                  NH Zurbano           \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouplevel</th>\n",
       "      <th>Service</th>\n",
       "      <th>ENTRY_DATE</th>\n",
       "      <th>ENTRY_HOUR</th>\n",
       "      <th>ACTIVITY_ID</th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>Alias</th>\n",
       "      <th>AGENT_DISTRIBUTED</th>\n",
       "      <th>DISTRIBUTED_DATE</th>\n",
       "      <th>DISTRIBUTED_HOUR</th>\n",
       "      <th>...</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>due_on</th>\n",
       "      <th>from_mail</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>REAL_TIME_ACTIVITY</th>\n",
       "      <th>MATCH</th>\n",
       "      <th>MATCH LEVEL</th>\n",
       "      <th>PAIS</th>\n",
       "      <th>CIUDAD</th>\n",
       "      <th>HOTEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:31:11</td>\n",
       "      <td>122175699</td>\n",
       "      <td>109038051</td>\n",
       "      <td>EDS.RESERVIERUNGEN@NH-HOTELS.COM</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:37:26</td>\n",
       "      <td>...</td>\n",
       "      <td>Finished by system</td>\n",
       "      <td>15/05/2024 01:31:11</td>\n",
       "      <td>CONNECTIVITY_SUPPORT@NH-HOTELS.COM</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>at09.atter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AUSTRIA</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NH Collection Wien Zentrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:22:45</td>\n",
       "      <td>122175656</td>\n",
       "      <td>109038230</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:23</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 01:22:45</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:11</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:34:37</td>\n",
       "      <td>122175417</td>\n",
       "      <td>109038252</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:34:37</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:01:33</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:39:28</td>\n",
       "      <td>122175448</td>\n",
       "      <td>109038264</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:38:24</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:39:28</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>nh lyon airport</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NH Lyon Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CRO</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>22:46:50</td>\n",
       "      <td>122175485</td>\n",
       "      <td>109038284</td>\n",
       "      <td>eds.reservas@nh-hotels.com</td>\n",
       "      <td>SYSTEM SYSTEM</td>\n",
       "      <td>12/05/2024</td>\n",
       "      <td>23:41:38</td>\n",
       "      <td>...</td>\n",
       "      <td>Finish Transaction</td>\n",
       "      <td>15/05/2024 00:46:50</td>\n",
       "      <td>discovery@gha.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>nh madrid zurbano</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NH Zurbano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grouplevel Service  ENTRY_DATE ENTRY_HOUR  ACTIVITY_ID    CASE_ID  \\\n",
       "0           0     CRO  12/05/2024   23:31:11    122175699  109038051   \n",
       "1           0     CRO  12/05/2024   23:22:45    122175656  109038230   \n",
       "2           0     CRO  12/05/2024   22:34:37    122175417  109038252   \n",
       "3           0     CRO  12/05/2024   22:39:28    122175448  109038264   \n",
       "4           0     CRO  12/05/2024   22:46:50    122175485  109038284   \n",
       "\n",
       "                              Alias AGENT_DISTRIBUTED DISTRIBUTED_DATE  \\\n",
       "0  EDS.RESERVIERUNGEN@NH-HOTELS.COM     SYSTEM SYSTEM       12/05/2024   \n",
       "1        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "2        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "3        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "4        eds.reservas@nh-hotels.com     SYSTEM SYSTEM       12/05/2024   \n",
       "\n",
       "  DISTRIBUTED_HOUR  ...             Subtype               due_on  \\\n",
       "0         23:37:26  ...  Finished by system  15/05/2024 01:31:11   \n",
       "1         23:38:23  ...  Finish Transaction  15/05/2024 01:22:45   \n",
       "2         23:38:24  ...  Finish Transaction  15/05/2024 00:34:37   \n",
       "3         23:38:24  ...  Finish Transaction  15/05/2024 00:39:28   \n",
       "4         23:41:38  ...  Finish Transaction  15/05/2024 00:46:50   \n",
       "\n",
       "                            from_mail DIRECTION REAL_TIME_ACTIVITY  \\\n",
       "0  CONNECTIVITY_SUPPORT@NH-HOTELS.COM        IN           00:00:00   \n",
       "1                   discovery@gha.com        IN           00:02:11   \n",
       "2                   discovery@gha.com        IN           00:01:33   \n",
       "3                   discovery@gha.com        IN           00:02:17   \n",
       "4                   discovery@gha.com        IN           00:00:00   \n",
       "\n",
       "               MATCH MATCH LEVEL     PAIS  CIUDAD                       HOTEL  \n",
       "0         at09.atter         2.0  AUSTRIA  Vienna  NH Collection Wien Zentrum  \n",
       "1    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "2    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "3    nh lyon airport         3.0   FRANCE    Lyon             NH Lyon Airport  \n",
       "4  nh madrid zurbano         3.0    SPAIN  Madrid                  NH Zurbano  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1007.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo datos del archivo de día:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(inicio_dia),int(fin_dia)+1):\n",
    "    if i <10: \n",
    "        Day = \"0\"+str(i)\n",
    "        print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "        with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+year+mes+Day+'.csv') as f:\n",
    "            doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "        doc = doc.iloc[:,1:]\n",
    "        doc.columns=['Service',\n",
    "                    'Entry_date',\n",
    "                    'Entry_hour',\n",
    "                    'Activity_ID',\n",
    "                    'Case_ID',\n",
    "                    'Alias',\n",
    "                    'Agent_distributed',\n",
    "                    'Distributed_date',\n",
    "                    'Distributed_hour',\n",
    "                    'Queue',\n",
    "                    'Completed',\n",
    "                    'Agent_completed',\n",
    "                    'Completed_date',\n",
    "                    'Completed_hour',\n",
    "                    'Type',\n",
    "                    'Subtype',\n",
    "                    'due_on',\n",
    "                    'From_mail',\n",
    "                    'IN_OUT',\n",
    "                    'Total_time',\n",
    "                    'Match',\n",
    "                    'Match_level',\n",
    "                    'Country',\n",
    "                    'City',\n",
    "                    'Hotel'\n",
    "                    # 'Hotel_Id'\n",
    "                    ]\n",
    "        # doc.insert(20,'Match','KKKKK')\n",
    "        doc.insert(25,'Hotel_Id','')\n",
    "        raw = doc.astype(str)\n",
    "        raw = raw.loc[:,['Service',\n",
    "                'Entry_date',\n",
    "                'Entry_hour',\n",
    "                'Activity_ID',\n",
    "                'Case_ID',\n",
    "                'Alias',\n",
    "                'Agent_distributed',\n",
    "                'Distributed_date',\n",
    "                'Distributed_hour',\n",
    "                'Queue',\n",
    "                'Completed',\n",
    "                'Agent_completed',\n",
    "                'Completed_date',\n",
    "                'Completed_hour',\n",
    "                'Type',\n",
    "                'Subtype',\n",
    "                'due_on',\n",
    "                'From_mail',\n",
    "                'IN_OUT',\n",
    "                'Total_time',\n",
    "                'Match',\n",
    "                'Match_level',\n",
    "                'Country',\n",
    "                'City',\n",
    "                'Hotel',\n",
    "                'Hotel_Id'\n",
    "                ]]\n",
    "        raw.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "        raw[\"Entry_date\"] = pd.to_datetime(raw[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw[\"Completed_date\"] = pd.to_datetime(raw[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw[\"Distributed_date\"] = pd.to_datetime(raw[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw.to_gbq(destination_table='Evolution.SLA_completed_Hotel_pdf',project_id='nh-cro-forecast', if_exists='append')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    else:\n",
    "        Day = str(i)\n",
    "        print(f\"Subiendo datos del archivo de día:{Day}\")\n",
    "        with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+year+mes+Day+'.csv') as f:\n",
    "            doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "        doc = doc.iloc[:,1:]\n",
    "        doc.columns=['Service',\n",
    "                    'Entry_date',\n",
    "                    'Entry_hour',\n",
    "                    'Activity_ID',\n",
    "                    'Case_ID',\n",
    "                    'Alias',\n",
    "                    'Agent_distributed',\n",
    "                    'Distributed_date',\n",
    "                    'Distributed_hour',\n",
    "                    'Queue',\n",
    "                    'Completed',\n",
    "                    'Agent_completed',\n",
    "                    'Completed_date',\n",
    "                    'Completed_hour',\n",
    "                    'Type',\n",
    "                    'Subtype',\n",
    "                    'due_on',\n",
    "                    'From_mail',\n",
    "                    'IN_OUT',\n",
    "                    'Total_time',\n",
    "                    'Match',\n",
    "                    'Match_level',\n",
    "                    'Country',\n",
    "                    'City',\n",
    "                    'Hotel'\n",
    "                    # 'Hotel_Id'\n",
    "                    ]\n",
    "        # doc.insert(20,'Match','KKKKK')\n",
    "        doc.insert(25,'Hotel_Id','')\n",
    "        raw = doc.astype(str)\n",
    "        raw = raw.loc[:,['Service',\n",
    "                'Entry_date',\n",
    "                'Entry_hour',\n",
    "                'Activity_ID',\n",
    "                'Case_ID',\n",
    "                'Alias',\n",
    "                'Agent_distributed',\n",
    "                'Distributed_date',\n",
    "                'Distributed_hour',\n",
    "                'Queue',\n",
    "                'Completed',\n",
    "                'Agent_completed',\n",
    "                'Completed_date',\n",
    "                'Completed_hour',\n",
    "                'Type',\n",
    "                'Subtype',\n",
    "                'due_on',\n",
    "                'From_mail',\n",
    "                'IN_OUT',\n",
    "                'Total_time',\n",
    "                'Match',\n",
    "                'Match_level',\n",
    "                'Country',\n",
    "                'City',\n",
    "                'Hotel',\n",
    "                'Hotel_Id'\n",
    "                ]]\n",
    "        raw.replace(['NaN','None','NaT',' ','nan'],[None,None,None,None,None],inplace=True)\n",
    "        raw[\"Entry_date\"] = pd.to_datetime(raw[\"Entry_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw[\"Completed_date\"] = pd.to_datetime(raw[\"Completed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw[\"Distributed_date\"] = pd.to_datetime(raw[\"Distributed_date\"], format = '%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "        raw.to_gbq(destination_table='Evolution.SLA_completed_Hotel_pdf',project_id='nh-cro-forecast', if_exists='append')\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+year+mes+Day+'.csv') as f:\n",
    "    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "doc = doc.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11075 entries, 0 to 11074\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Service             11075 non-null  object \n",
      " 1   ENTRY_DATE          11075 non-null  object \n",
      " 2   ENTRY_HOUR          11075 non-null  object \n",
      " 3   ACTIVITY_ID         11075 non-null  int64  \n",
      " 4   CASE_ID             11075 non-null  int64  \n",
      " 5   Alias               6448 non-null   object \n",
      " 6   AGENT_DISTRIBUTED   11075 non-null  object \n",
      " 7   DISTRIBUTED_DATE    11075 non-null  object \n",
      " 8   DISTRIBUTED_HOUR    11075 non-null  object \n",
      " 9   QUEUE               11075 non-null  object \n",
      " 10  COMPLETED           11075 non-null  object \n",
      " 11  AGENT_COMPLETED     11075 non-null  object \n",
      " 12  COMPLETED_DATE      11075 non-null  object \n",
      " 13  COMPLETED_HOUR      11075 non-null  object \n",
      " 14  Type                11075 non-null  object \n",
      " 15  Subtype             11075 non-null  object \n",
      " 16  due_on              11075 non-null  object \n",
      " 17  from_mail           11075 non-null  object \n",
      " 18  DIRECTION           11075 non-null  object \n",
      " 19  REAL_TIME_ACTIVITY  11075 non-null  object \n",
      " 20  MATCH               7446 non-null   object \n",
      " 21  MATCH LEVEL         7446 non-null   float64\n",
      " 22  PAIS                7417 non-null   object \n",
      " 23  CIUDAD              7332 non-null   object \n",
      " 24  HOTEL               6936 non-null   object \n",
      " 25  ID                  7446 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(22)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "doc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12927 entries, 0 to 12926\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Service            12927 non-null  object\n",
      " 1   Entry_date         12927 non-null  object\n",
      " 2   Entry_hour         12927 non-null  object\n",
      " 3   Activity_ID        12927 non-null  object\n",
      " 4   Case_ID            12927 non-null  object\n",
      " 5   Alias              7496 non-null   object\n",
      " 6   Agent_distributed  12927 non-null  object\n",
      " 7   Distributed_date   12927 non-null  object\n",
      " 8   Distributed_hour   12927 non-null  object\n",
      " 9   Queue              12927 non-null  object\n",
      " 10  Completed          12927 non-null  object\n",
      " 11  Agent_completed    12927 non-null  object\n",
      " 12  Completed_date     12927 non-null  object\n",
      " 13  Completed_hour     12927 non-null  object\n",
      " 14  Type               12927 non-null  object\n",
      " 15  Subtype            12927 non-null  object\n",
      " 16  due_on             12927 non-null  object\n",
      " 17  From_mail          12927 non-null  object\n",
      " 18  IN_OUT             12927 non-null  object\n",
      " 19  Total_time         12927 non-null  object\n",
      " 20  Match              12927 non-null  object\n",
      " 21  Match_level        8095 non-null   object\n",
      " 22  Country            8065 non-null   object\n",
      " 23  City               7957 non-null   object\n",
      " 24  Hotel              7465 non-null   object\n",
      " 25  Hotel_ID           12927 non-null  object\n",
      "dtypes: object(26)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open('trueit_external/SLA_Completed_Hotel/SLA_Completed_Hotel_'+year+mes+Day+'.csv') as f:\n",
    "    doc = pd.read_csv(f,delimiter = ';', encoding='latin-1')\n",
    "doc = doc.iloc[:,1:]\n",
    "doc.columns=['Service',\n",
    "            'Entry_date',\n",
    "            'Entry_hour',\n",
    "            'Activity_ID',\n",
    "            'Case_ID',\n",
    "            'Alias',\n",
    "            'Agent_distributed',\n",
    "            'Distributed_date',\n",
    "            'Distributed_hour',\n",
    "            'Queue',\n",
    "            'Completed',\n",
    "            'Agent_completed',\n",
    "            'Completed_date',\n",
    "            'Completed_hour',\n",
    "            'Type',\n",
    "            'Subtype',\n",
    "            'due_on',\n",
    "            'From_mail',\n",
    "            'IN_OUT',\n",
    "            'Total_time',\n",
    "            # 'Match',\n",
    "            'Match_level',\n",
    "            'Country',\n",
    "            'City',\n",
    "            'Hotel',\n",
    "            # 'Hotel_ID'\n",
    "            ]\n",
    "doc.insert(20,'Match','KKKKK')\n",
    "doc.insert(25,'Hotel_ID','KKKKK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12927 entries, 0 to 12926\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Service            12927 non-null  object\n",
      " 1   Entry_date         12927 non-null  object\n",
      " 2   Entry_hour         12927 non-null  object\n",
      " 3   Activity_ID        12927 non-null  int64 \n",
      " 4   Case_ID            12927 non-null  int64 \n",
      " 5   Alias              7496 non-null   object\n",
      " 6   Agent_distributed  12927 non-null  object\n",
      " 7   Distributed_date   12927 non-null  object\n",
      " 8   Distributed_hour   12927 non-null  object\n",
      " 9   Queue              12927 non-null  object\n",
      " 10  Completed          12927 non-null  object\n",
      " 11  Agent_completed    12927 non-null  object\n",
      " 12  Completed_date     12927 non-null  object\n",
      " 13  Completed_hour     12927 non-null  object\n",
      " 14  Type               12927 non-null  object\n",
      " 15  Subtype            12927 non-null  object\n",
      " 16  due_on             12927 non-null  object\n",
      " 17  From_mail          12927 non-null  object\n",
      " 18  IN_OUT             12927 non-null  object\n",
      " 19  Total_time         12927 non-null  object\n",
      " 20  Match              12927 non-null  object\n",
      " 21  Match_level        8095 non-null   object\n",
      " 22  Country            8065 non-null   object\n",
      " 23  City               7957 non-null   object\n",
      " 24  Hotel              7465 non-null   object\n",
      " 25  Hotel_ID           12927 non-null  object\n",
      "dtypes: int64(2), object(24)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "doc.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
